{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Course Information Course Supervisor Dr. P\u00e9ter Galambos peter.galambos@irob.uni-obuda.hu Teachers Tam\u00e1s D. Nagy tamas.daniel.nagy@irob.uni-obuda.hu Borsa D\u00e9t\u00e1r detar.borsa@gmail.com Schedule Week Date Topic Test 2. March 7 Course requirements. Introduction, System setup. - 4. March 21 Linux, ROS introduction. - 5. March 28 Python principles, ROS Publisher, ROS Subscriber. Projekt labor I. - 6. April 4 ROS 2 Launch, ROS 2 Param, ROS 2 Bag. - 8. April 18 Git. Project lab I. - 9. April 25 Principles of robotics, da Vinci I. - 10. May 2 Principles of robotics, da Vinci II. - 11. May 9 Kinematics, Inverse kinematics I. - 12. May 16 Kinematics, Inverse kinematics II. - 13. May 23 Project lab II. - 14. May 30 Project presentations. Test 14+1. June 6 - Test retake Warning The schedule may change during the semester! Course Requirements Project Proved to be the student's own work Running results valid output Grading: completeness of the soultion, proper ROS communication, proper structure of the program, quality of implementation, documentation Grading Personal attendance on the classes is mandatory (min 70%). To pass the course, Tests and the Project must be passed (grade 2). One of the Test can be taken again. Grade \\(Grade = (Test1 + Test2 + 2 \\times Project) / 4\\) Antal Bejczy Center for Intelligent Robotics (BARK/IROB) https://irob.uni-obuda.hu irob-saf (iRob Surgical Automation Framework) https://github.com/ABC-iRobotics/irob-saf PlatypOUs https://github.com/ABC-iRobotics/PlatypOUs-Mobile-Robot-Platform","title":"Home"},{"location":"#course-information","text":"","title":"Course Information"},{"location":"#course-supervisor","text":"Dr. P\u00e9ter Galambos peter.galambos@irob.uni-obuda.hu","title":"Course Supervisor"},{"location":"#teachers","text":"Tam\u00e1s D. Nagy tamas.daniel.nagy@irob.uni-obuda.hu Borsa D\u00e9t\u00e1r detar.borsa@gmail.com","title":"Teachers"},{"location":"#schedule","text":"Week Date Topic Test 2. March 7 Course requirements. Introduction, System setup. - 4. March 21 Linux, ROS introduction. - 5. March 28 Python principles, ROS Publisher, ROS Subscriber. Projekt labor I. - 6. April 4 ROS 2 Launch, ROS 2 Param, ROS 2 Bag. - 8. April 18 Git. Project lab I. - 9. April 25 Principles of robotics, da Vinci I. - 10. May 2 Principles of robotics, da Vinci II. - 11. May 9 Kinematics, Inverse kinematics I. - 12. May 16 Kinematics, Inverse kinematics II. - 13. May 23 Project lab II. - 14. May 30 Project presentations. Test 14+1. June 6 - Test retake Warning The schedule may change during the semester!","title":"Schedule"},{"location":"#course-requirements","text":"","title":"Course Requirements"},{"location":"#project","text":"Proved to be the student's own work Running results valid output Grading: completeness of the soultion, proper ROS communication, proper structure of the program, quality of implementation, documentation","title":"Project"},{"location":"#grading","text":"Personal attendance on the classes is mandatory (min 70%). To pass the course, Tests and the Project must be passed (grade 2). One of the Test can be taken again. Grade \\(Grade = (Test1 + Test2 + 2 \\times Project) / 4\\)","title":"Grading"},{"location":"#antal-bejczy-center-for-intelligent-robotics-barkirob","text":"https://irob.uni-obuda.hu","title":"Antal Bejczy Center for Intelligent Robotics (BARK/IROB)"},{"location":"#irob-saf","text":"(iRob Surgical Automation Framework) https://github.com/ABC-iRobotics/irob-saf","title":"irob-saf"},{"location":"#platypous","text":"https://github.com/ABC-iRobotics/PlatypOUs-Mobile-Robot-Platform","title":"PlatypOUs"},{"location":"01_system_setup/","text":"01. Introduction Robot Operating System (ROS) introduction Robot definition Joseph Engelberger, pioneer in industrial robotics: \"I can't define a robot, but I know one when I see one.\" Wikipedia: \"A robot is a machine\u2014especially one programmable by a computer\u2014 capable of carrying out a complex series of actions automatically. Robots can be guided by an external control device or the control may be embedded within. Robots may be constructed on the lines of human form, but most robots are machines designed to perform a task with no regard to their aesthetics.\" ISO 8373:2012 Robots and robotic devices \u2013 Vocabulary, FDIS 2012: \"A robot is an actuated mechanism programmable in two or more axes with a degree of autonomy, moving within its environment, to perform intended tasks.\" Rodney Brooks, Founder and CTO, Rethink Robotics: \"A robot is some sort of device, wich has sensors those sensors the world, does some sort of computation, decides on an action, and then does that action based on the sensory input, which makes some change out in the world, outside its body. Comment: the part \"make some change outside its body\" discriminates a washing machine from e.g. a Roomba.\" Tam\u00e1s Haidegger, Encyclopedia of Robotics : \"A robot is a complex mechatronic system enabled with electronics, sensors, actuators and software, executing tasks with a certain degree of autonomy. It may be pre-programmed, teleoperated or carrying out computations to make decisions.\" What is ROS? Open-source, robotics themed middleware Modularity, reusability (drivers, algorithms, libraries, ...) Hardware abstraction, ROS API C++ \u00e9s Python support Ubuntu Linux (except ROS 2) Great community History Mid 2000s, Stanford: robotics themed, flexible, dynamic framework for prototype development 2007, Willow Garage: incubation, the core of ROS under BSD license Spread in robotics research, PR2 2012: Industrial robotics, ROS-Industrial 2017: ROS 2 Development system build -- homework Recommended environment: Ubuntu 20.04 ROS1 Noetic ROS2 Foxy IDE: QtCreator/CLion/VSCode ROS 1 Noetic Install ROS Noetic sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list' sudo apt install curl curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add - sudo apt update sudo apt install ros-noetic-desktop-full source /opt/ros/noetic/setup.bash ROS 1 dependencies sudo apt install python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wstool build-essential sudo rosdep init rosdep update Once we are done with this, we can test our ROS 1 installation with the following command: source /opt/ros/noetic/setup.bash roscore ROS 2 Foxy Setup locale. locale # check for UTF-8 sudo apt update && sudo apt install locales sudo locale-gen en_US en_US.UTF-8 sudo update-locale LC_ALL = en_US.UTF-8 LANG = en_US.UTF-8 export LANG = en_US.UTF-8 locale # verify settings Install ROS 2 Foxy sudo apt install software-properties-common sudo add-apt-repository universe sudo apt update && sudo apt install curl sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg echo \"deb [arch= $( dpkg --print-architecture ) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $( . /etc/os-release && echo $UBUNTU_CODENAME ) main\" | sudo tee /etc/apt/sources.list.d/ros2.list > /dev/null sudo apt update sudo apt upgrade sudo apt install ros-foxy-desktop python3-argcomplete ros-dev-tools ros-foxy-moveit* ros-foxy-control* Once we are done with this, we can test our ROS 2 installation with the following command: source /opt/ros/foxy/setup.bash ros2 run demo_nodes_py talker The source command is responsible for setting the environment variables, which must be entered every time a new terminal window is opened. This command can be pasted at the end of the ~/.bashrc file, which will run every time a terminal window is opened, so we don't have to type it all the time (ROS 2 will be the default): echo \"source /opt/ros/foxy/setup.bash\" >> ~/.bashrc Further packages The following packages will also be needed during the semester, so it is worth installing them as well: sudo apt install libxml2-dev libraw1394-dev libncurses5-dev qtcreator swig sox espeak cmake-curses-gui cmake-qt-gui git subversion gfortran libcppunit-dev libqt5xmlpatterns5-dev python3-catkin-tools python3-osrf-pycommon libasound2-dev libgl1-mesa-dev xorg-dev ros-foxy-turtlebot3* IDE QtCreator QtCreator is currently one of the most usable IDEs for developing ROS packages, for which a ROS plugin has also been created. The installer is available at the link below. You should use the \"18.04 offline installer\", it also works on Ubunutu 20.04. https://ros-qtc-plugin.readthedocs.io/en/latest/_source/How-to-Install-Users.html Once downloaded, the IDE can be installed with the following command (it is important to insert cd in the download location): ```bash chmod +x qtcreator-ros-bionic-latest-offline-installer.run sudo ./qtcreator-ros-bionic-latest-offline-installer.run ``` When the installer asks where to install it, change to e.g `/home/<USER>/QtCreator` mapp\u00e1ra. Ha a root-ba tel\u00e9ep\u00edtj\u00fck, nem fogjuk tudni futtatni. A telep\u00edt\u00e9s ut\u00e1n \"Qt Creator (4.9.2)\" n\u00e9ven keress\u00fck. --- CLion CLion has a high degree of ROS integration, the use of which is the most recommended during the course. A free student license can be requested at the following link: https://www.jetbrains.com/community/education/#students After installation, find the /var/lib/snapd/desktop/applications/clion_clion.desktop file. We rewrite the appropriate line for this, so the environment set by the terminal will be used by the IDE: ```bash Exec=bash -i -c \"/snap/bin/clion\" %f ``` --- Visual Studio Microsoft Visual Studio also supports source codes for ROS, this IDE can also be used during the semester. Suggestion Install Terminator terminal emulator: sudo apt update sudo apt install terminator Useful links https://www.ros.org/ ROS 1 Noetic installation ROS 2 Foxy installation ROS Distributions http://wiki.ros.org/ROS/Tutorials CLion hallgat\u00f3i licensz QtCreator + ROS plugin IROB virtual tour","title":"1. Introduction, System setup"},{"location":"01_system_setup/#01-introduction","text":"","title":"01. Introduction"},{"location":"01_system_setup/#robot-operating-system-ros-introduction","text":"","title":"Robot Operating System (ROS) introduction"},{"location":"01_system_setup/#robot-definition","text":"Joseph Engelberger, pioneer in industrial robotics: \"I can't define a robot, but I know one when I see one.\" Wikipedia: \"A robot is a machine\u2014especially one programmable by a computer\u2014 capable of carrying out a complex series of actions automatically. Robots can be guided by an external control device or the control may be embedded within. Robots may be constructed on the lines of human form, but most robots are machines designed to perform a task with no regard to their aesthetics.\" ISO 8373:2012 Robots and robotic devices \u2013 Vocabulary, FDIS 2012: \"A robot is an actuated mechanism programmable in two or more axes with a degree of autonomy, moving within its environment, to perform intended tasks.\" Rodney Brooks, Founder and CTO, Rethink Robotics: \"A robot is some sort of device, wich has sensors those sensors the world, does some sort of computation, decides on an action, and then does that action based on the sensory input, which makes some change out in the world, outside its body. Comment: the part \"make some change outside its body\" discriminates a washing machine from e.g. a Roomba.\" Tam\u00e1s Haidegger, Encyclopedia of Robotics : \"A robot is a complex mechatronic system enabled with electronics, sensors, actuators and software, executing tasks with a certain degree of autonomy. It may be pre-programmed, teleoperated or carrying out computations to make decisions.\"","title":"Robot definition"},{"location":"01_system_setup/#what-is-ros","text":"Open-source, robotics themed middleware Modularity, reusability (drivers, algorithms, libraries, ...) Hardware abstraction, ROS API C++ \u00e9s Python support Ubuntu Linux (except ROS 2) Great community","title":"What is ROS?"},{"location":"01_system_setup/#history","text":"Mid 2000s, Stanford: robotics themed, flexible, dynamic framework for prototype development 2007, Willow Garage: incubation, the core of ROS under BSD license Spread in robotics research, PR2 2012: Industrial robotics, ROS-Industrial 2017: ROS 2","title":"History"},{"location":"01_system_setup/#development-system-build-homework","text":"Recommended environment: Ubuntu 20.04 ROS1 Noetic ROS2 Foxy IDE: QtCreator/CLion/VSCode","title":"Development system build -- homework"},{"location":"01_system_setup/#ros-1-noetic","text":"Install ROS Noetic sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list' sudo apt install curl curl -s https://raw.githubusercontent.com/ros/rosdistro/master/ros.asc | sudo apt-key add - sudo apt update sudo apt install ros-noetic-desktop-full source /opt/ros/noetic/setup.bash ROS 1 dependencies sudo apt install python3-rosdep python3-rosinstall python3-rosinstall-generator python3-wstool build-essential sudo rosdep init rosdep update Once we are done with this, we can test our ROS 1 installation with the following command: source /opt/ros/noetic/setup.bash roscore","title":"ROS 1 Noetic"},{"location":"01_system_setup/#ros-2-foxy","text":"Setup locale. locale # check for UTF-8 sudo apt update && sudo apt install locales sudo locale-gen en_US en_US.UTF-8 sudo update-locale LC_ALL = en_US.UTF-8 LANG = en_US.UTF-8 export LANG = en_US.UTF-8 locale # verify settings Install ROS 2 Foxy sudo apt install software-properties-common sudo add-apt-repository universe sudo apt update && sudo apt install curl sudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg echo \"deb [arch= $( dpkg --print-architecture ) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $( . /etc/os-release && echo $UBUNTU_CODENAME ) main\" | sudo tee /etc/apt/sources.list.d/ros2.list > /dev/null sudo apt update sudo apt upgrade sudo apt install ros-foxy-desktop python3-argcomplete ros-dev-tools ros-foxy-moveit* ros-foxy-control* Once we are done with this, we can test our ROS 2 installation with the following command: source /opt/ros/foxy/setup.bash ros2 run demo_nodes_py talker The source command is responsible for setting the environment variables, which must be entered every time a new terminal window is opened. This command can be pasted at the end of the ~/.bashrc file, which will run every time a terminal window is opened, so we don't have to type it all the time (ROS 2 will be the default): echo \"source /opt/ros/foxy/setup.bash\" >> ~/.bashrc","title":"ROS 2 Foxy"},{"location":"01_system_setup/#further-packages","text":"The following packages will also be needed during the semester, so it is worth installing them as well: sudo apt install libxml2-dev libraw1394-dev libncurses5-dev qtcreator swig sox espeak cmake-curses-gui cmake-qt-gui git subversion gfortran libcppunit-dev libqt5xmlpatterns5-dev python3-catkin-tools python3-osrf-pycommon libasound2-dev libgl1-mesa-dev xorg-dev ros-foxy-turtlebot3*","title":"Further packages"},{"location":"01_system_setup/#ide","text":"QtCreator QtCreator is currently one of the most usable IDEs for developing ROS packages, for which a ROS plugin has also been created. The installer is available at the link below. You should use the \"18.04 offline installer\", it also works on Ubunutu 20.04. https://ros-qtc-plugin.readthedocs.io/en/latest/_source/How-to-Install-Users.html Once downloaded, the IDE can be installed with the following command (it is important to insert cd in the download location): ```bash chmod +x qtcreator-ros-bionic-latest-offline-installer.run sudo ./qtcreator-ros-bionic-latest-offline-installer.run ``` When the installer asks where to install it, change to e.g `/home/<USER>/QtCreator` mapp\u00e1ra. Ha a root-ba tel\u00e9ep\u00edtj\u00fck, nem fogjuk tudni futtatni. A telep\u00edt\u00e9s ut\u00e1n \"Qt Creator (4.9.2)\" n\u00e9ven keress\u00fck. --- CLion CLion has a high degree of ROS integration, the use of which is the most recommended during the course. A free student license can be requested at the following link: https://www.jetbrains.com/community/education/#students After installation, find the /var/lib/snapd/desktop/applications/clion_clion.desktop file. We rewrite the appropriate line for this, so the environment set by the terminal will be used by the IDE: ```bash Exec=bash -i -c \"/snap/bin/clion\" %f ``` --- Visual Studio Microsoft Visual Studio also supports source codes for ROS, this IDE can also be used during the semester. Suggestion Install Terminator terminal emulator: sudo apt update sudo apt install terminator","title":"IDE"},{"location":"01_system_setup/#useful-links","text":"https://www.ros.org/ ROS 1 Noetic installation ROS 2 Foxy installation ROS Distributions http://wiki.ros.org/ROS/Tutorials CLion hallgat\u00f3i licensz QtCreator + ROS plugin IROB virtual tour","title":"Useful links"},{"location":"02_linux_ros_principles/","text":"02. Linux, ROS introduction Lecture Linux principles (Was) the only OS supported by ROS Security Efficieny Open-source Community support User freedom Distributions: Ubuntu , Linux Mint, Debian, etc. Terminal usage more dominant Suggestion Install Terminator terminal emulator: sudo apt update sudo apt install terminator Linux commands See some basic commands below: Run as administrator with sudo Manual of command man , e.g. man cp Package management apt , e.g. apt update , apt install Navigation cd List directory contents ls Create file touch Copy file cp Move file mv Remove file rm Make directory mkdir Remove directory rmdir Make a file executable chmod +x <filename> Safe restart: Crtl + Alt + PrtScr + REISUB If not sure, just google the command ROS 1 \u2192 ROS 2 ROS 2 was rewritten from scratch More modular architecture Improved support for real-time systems Support for multiple communication protocols Better interoperability with other robotic systems Focus on standardization and industry collaboration No ROS Master No Devel space rclpy , rclcpp More structured code ( Node class) Different build system Platforms: Windows, OS X, Linux ROS principles ROS workspace Colcon workspace A folder where packages are modified, built, and installed. Source space: Source code of colcon packages Space where you can extract/checkout/clone source code for the packages you want to build Build space Colcon is invoked here to build packages Colcon and CMake keep intermediate files here Install space: Each package will be installed here; by default each package will be installed into a separate subdirectory Log space: Contains various logging information about each colcon invocation ROS package principle Enough functionality to be useful, but not too much that the package is heavyweight and difficult to use from other software. ROS dependencies After cloning a new package, use the following command to install depenencies: rosdep install --from-paths src --ignore-src -r -y ROS package Main unit to organize software in ROS Buildable and redistributable unit of ROS code Consists of (in the case of Python packages): package.xml file containing meta information about the package name version description dependencies etc. setup.py containing instructions for how to install the package setup.cfg is required when a package has executables, so ros2 run can find them /<package_name> - a directory with the same name as your package, used by ROS 2 tools to find your package, contains __init__.py Anything else ros2 run turtlesim turtlesim_node CMake For CMake packages (C++), the package contents will be different. ROS node Executable part of ROS: python scripts compiled C++ code A process that performs computation Inter-node communication: ROS topics (streams) ROS parameter server Remote Procedure Calls (RPC) ROS services ROS actions Meant to operate at a fine-grained scale Typically, a robot control system consists of many nodes, like: Trajectory planning Localization Read sensory data Process sensory data Motor control User interface etc. ROS build system---Colcon System for building software packages in ROS Environmental setup file setup.bash generated during init process of a new workspace extends shell environment ROS can find any resources that have been installed or built to that location source ~/ros2_ws/install/setup.bash Practice 1: Turtlesim Start turtlesim_node and turtle_teleop_key nodes with the following commands, in separate terminal windows: ros2 run turtlesim turtlesim_node ros2 run turtlesim turtle_teleop_key Tip In Terminator , you can further divide the given window with Ctrl-Shift-O, Ctrl-Shift-E key combinations. Ctrl-Shift-W closes the active window. Abort execution Ctrl-C Running the following ROS commands can provide useful information: ros2 wtf ros2 node list ros2 node info /turtlesim ros2 topic list ros2 topic info /turtle1/cmd_vel ros2 interface show geometry_msgs/msg/Twist ros2 topic echo /turtle1/cmd_vel Start rqt_gui with the following command: ros2 run rqt_gui rqt_gui Display the running nodes and topics in rqt_gui : Plugins \u2192 Introspection \u2192 Node Graph. Publish to the /turtle1/cmd_vel topic also using rqt_gui : Plugins \u2192 Topics \u2192 Message Publisher. 2: ROS 2 workspace creation Let's create a new ROS2 workspace with the name ros2_ws . mkdir -p ~/ros2_ws/src 3: ROS 2 package creation Let's create a new ROS2 package with the name ros2_course and a Hello World. cd ~/ros2_ws/src ros2 pkg create --build-type ament_python --node-name hello ros2_course Syntax ros2 pkg create --build-type ament_python <package_name> Build the workspace. cd ~/ros2_ws colcon build --symlink-install Symlink The option --symlink-install links the source scripts to the Install space, so we don't have to build again after modification. Insert the following line at the end of the ~/.bashrc file: source ~/ros2_ws/install/setup.bash Import to QtCreator New file or project \u2192 Other project \u2192 ROS Workspace. Select Colcon as Build System and ros2_ws as Workspace path. Import to CLion Set the Python interpreter to Python 3.8, /usr/bin/python3 . Add the follwong path: /opt/ros/foxy/lib/python3.8/site-packages . Hozzuk l\u00e9tre a compile_commands.json f\u00e1jlt a ~/ros2_ws/build k\u00f6nyvt\u00e1rban az al\u00e1bbi tartalommal: [ ] Test Hello World: ros2 run ros2_course hello 4: Implementing a Publisher in Python Navigate to the ros2_ws/src/ros2_course/ros2_course folder and create the talker.py file with the content below. import rclpy from rclpy.node import Node from std_msgs.msg import String class MinimalPublisher ( Node ): def __init__ ( self ): super () . __init__ ( 'minimal_publisher' ) self . publisher_ = self . create_publisher ( String , 'chatter' , 10 ) timer_period = 0.5 # seconds self . timer = self . create_timer ( timer_period , self . timer_callback ) self . i = 0 def timer_callback ( self ): msg = String () msg . data = 'Hello World: %d ' % self . i self . publisher_ . publish ( msg ) self . get_logger () . info ( 'Publishing: \" %s \"' % msg . data ) self . i += 1 def main ( args = None ): rclpy . init ( args = args ) minimal_publisher = MinimalPublisher () rclpy . spin ( minimal_publisher ) # Destroy the node explicitly # (optional - otherwise it will be done automatically # when the garbage collector destroys the node object) minimal_publisher . destroy_node () rclpy . shutdown () if __name__ == '__main__' : main () Add a new entry point in the setup.py file: 'talker = ros2_course.talker:main' , Build and run the node: cd ~/ros2_ws colcon build --symlink-install ros2 run ros2_course talker Check the output of the node using ros2 topic echo command or rqt_gui . 5: Implementing a Subscriber in Python Navigate to the ros2_ws/src/ros2_course/ros2_course folder and create the listener.py file with the content below. import rclpy from rclpy.node import Node from std_msgs.msg import String class MinimalSubscriber ( Node ): def __init__ ( self ): super () . __init__ ( 'minimal_subscriber' ) self . subscription = self . create_subscription ( String , 'chatter' , self . listener_callback , 10 ) self . subscription # prevent unused variable warning def listener_callback ( self , msg ): self . get_logger () . info ( 'I heard msg: \" %s \"' % msg . data ) def main ( args = None ): rclpy . init ( args = args ) minimal_subscriber = MinimalSubscriber () rclpy . spin ( minimal_subscriber ) # Destroy the node explicitly # (optional - otherwise it will be done automatically # when the garbage collector destroys the node object) minimal_subscriber . destroy_node () rclpy . shutdown () if __name__ == '__main__' : main () Add a new entry point in the setup.py file: 'listener = ros2_course.listener:main' , Build and run both nodes: cd ~/ros2_ws colcon build --symlink-install ros2 run ros2_course talker ros2 run ros2_course listener Use rqt_gui to display the nodes and topics of the running system: ros2 run rqt_gui rqt_gui Useful links ROS 2 Tutorials What is a ROS 2 package?","title":"2. Linux and ROS principles"},{"location":"02_linux_ros_principles/#02-linux-ros-introduction","text":"","title":"02. Linux, ROS introduction"},{"location":"02_linux_ros_principles/#lecture","text":"","title":"Lecture"},{"location":"02_linux_ros_principles/#linux-principles","text":"(Was) the only OS supported by ROS Security Efficieny Open-source Community support User freedom Distributions: Ubuntu , Linux Mint, Debian, etc. Terminal usage more dominant Suggestion Install Terminator terminal emulator: sudo apt update sudo apt install terminator","title":"Linux principles"},{"location":"02_linux_ros_principles/#linux-commands","text":"See some basic commands below: Run as administrator with sudo Manual of command man , e.g. man cp Package management apt , e.g. apt update , apt install Navigation cd List directory contents ls Create file touch Copy file cp Move file mv Remove file rm Make directory mkdir Remove directory rmdir Make a file executable chmod +x <filename> Safe restart: Crtl + Alt + PrtScr + REISUB If not sure, just google the command","title":"Linux commands"},{"location":"02_linux_ros_principles/#ros-1-ros-2","text":"ROS 2 was rewritten from scratch More modular architecture Improved support for real-time systems Support for multiple communication protocols Better interoperability with other robotic systems Focus on standardization and industry collaboration No ROS Master No Devel space rclpy , rclcpp More structured code ( Node class) Different build system Platforms: Windows, OS X, Linux","title":"ROS 1 &rarr; ROS 2"},{"location":"02_linux_ros_principles/#ros-principles","text":"","title":"ROS principles"},{"location":"02_linux_ros_principles/#ros-workspace","text":"Colcon workspace A folder where packages are modified, built, and installed. Source space: Source code of colcon packages Space where you can extract/checkout/clone source code for the packages you want to build Build space Colcon is invoked here to build packages Colcon and CMake keep intermediate files here Install space: Each package will be installed here; by default each package will be installed into a separate subdirectory Log space: Contains various logging information about each colcon invocation ROS package principle Enough functionality to be useful, but not too much that the package is heavyweight and difficult to use from other software. ROS dependencies After cloning a new package, use the following command to install depenencies: rosdep install --from-paths src --ignore-src -r -y","title":"ROS workspace"},{"location":"02_linux_ros_principles/#ros-package","text":"Main unit to organize software in ROS Buildable and redistributable unit of ROS code Consists of (in the case of Python packages): package.xml file containing meta information about the package name version description dependencies etc. setup.py containing instructions for how to install the package setup.cfg is required when a package has executables, so ros2 run can find them /<package_name> - a directory with the same name as your package, used by ROS 2 tools to find your package, contains __init__.py Anything else ros2 run turtlesim turtlesim_node CMake For CMake packages (C++), the package contents will be different.","title":"ROS package"},{"location":"02_linux_ros_principles/#ros-node","text":"Executable part of ROS: python scripts compiled C++ code A process that performs computation Inter-node communication: ROS topics (streams) ROS parameter server Remote Procedure Calls (RPC) ROS services ROS actions Meant to operate at a fine-grained scale Typically, a robot control system consists of many nodes, like: Trajectory planning Localization Read sensory data Process sensory data Motor control User interface etc.","title":"ROS node"},{"location":"02_linux_ros_principles/#ros-build-system-colcon","text":"System for building software packages in ROS","title":"ROS build system---Colcon"},{"location":"02_linux_ros_principles/#environmental-setup-file","text":"setup.bash generated during init process of a new workspace extends shell environment ROS can find any resources that have been installed or built to that location source ~/ros2_ws/install/setup.bash","title":"Environmental setup file"},{"location":"02_linux_ros_principles/#practice","text":"","title":"Practice"},{"location":"02_linux_ros_principles/#1-turtlesim","text":"Start turtlesim_node and turtle_teleop_key nodes with the following commands, in separate terminal windows: ros2 run turtlesim turtlesim_node ros2 run turtlesim turtle_teleop_key Tip In Terminator , you can further divide the given window with Ctrl-Shift-O, Ctrl-Shift-E key combinations. Ctrl-Shift-W closes the active window. Abort execution Ctrl-C Running the following ROS commands can provide useful information: ros2 wtf ros2 node list ros2 node info /turtlesim ros2 topic list ros2 topic info /turtle1/cmd_vel ros2 interface show geometry_msgs/msg/Twist ros2 topic echo /turtle1/cmd_vel Start rqt_gui with the following command: ros2 run rqt_gui rqt_gui Display the running nodes and topics in rqt_gui : Plugins \u2192 Introspection \u2192 Node Graph. Publish to the /turtle1/cmd_vel topic also using rqt_gui : Plugins \u2192 Topics \u2192 Message Publisher.","title":"1: Turtlesim"},{"location":"02_linux_ros_principles/#2-ros-2-workspace-creation","text":"Let's create a new ROS2 workspace with the name ros2_ws . mkdir -p ~/ros2_ws/src","title":"2: ROS 2 workspace creation"},{"location":"02_linux_ros_principles/#3-ros-2-package-creation","text":"Let's create a new ROS2 package with the name ros2_course and a Hello World. cd ~/ros2_ws/src ros2 pkg create --build-type ament_python --node-name hello ros2_course Syntax ros2 pkg create --build-type ament_python <package_name> Build the workspace. cd ~/ros2_ws colcon build --symlink-install Symlink The option --symlink-install links the source scripts to the Install space, so we don't have to build again after modification. Insert the following line at the end of the ~/.bashrc file: source ~/ros2_ws/install/setup.bash Import to QtCreator New file or project \u2192 Other project \u2192 ROS Workspace. Select Colcon as Build System and ros2_ws as Workspace path. Import to CLion Set the Python interpreter to Python 3.8, /usr/bin/python3 . Add the follwong path: /opt/ros/foxy/lib/python3.8/site-packages . Hozzuk l\u00e9tre a compile_commands.json f\u00e1jlt a ~/ros2_ws/build k\u00f6nyvt\u00e1rban az al\u00e1bbi tartalommal: [ ] Test Hello World: ros2 run ros2_course hello","title":"3: ROS 2 package creation"},{"location":"02_linux_ros_principles/#4-implementing-a-publisher-in-python","text":"Navigate to the ros2_ws/src/ros2_course/ros2_course folder and create the talker.py file with the content below. import rclpy from rclpy.node import Node from std_msgs.msg import String class MinimalPublisher ( Node ): def __init__ ( self ): super () . __init__ ( 'minimal_publisher' ) self . publisher_ = self . create_publisher ( String , 'chatter' , 10 ) timer_period = 0.5 # seconds self . timer = self . create_timer ( timer_period , self . timer_callback ) self . i = 0 def timer_callback ( self ): msg = String () msg . data = 'Hello World: %d ' % self . i self . publisher_ . publish ( msg ) self . get_logger () . info ( 'Publishing: \" %s \"' % msg . data ) self . i += 1 def main ( args = None ): rclpy . init ( args = args ) minimal_publisher = MinimalPublisher () rclpy . spin ( minimal_publisher ) # Destroy the node explicitly # (optional - otherwise it will be done automatically # when the garbage collector destroys the node object) minimal_publisher . destroy_node () rclpy . shutdown () if __name__ == '__main__' : main () Add a new entry point in the setup.py file: 'talker = ros2_course.talker:main' , Build and run the node: cd ~/ros2_ws colcon build --symlink-install ros2 run ros2_course talker Check the output of the node using ros2 topic echo command or rqt_gui .","title":"4: Implementing a Publisher in Python"},{"location":"02_linux_ros_principles/#5-implementing-a-subscriber-in-python","text":"Navigate to the ros2_ws/src/ros2_course/ros2_course folder and create the listener.py file with the content below. import rclpy from rclpy.node import Node from std_msgs.msg import String class MinimalSubscriber ( Node ): def __init__ ( self ): super () . __init__ ( 'minimal_subscriber' ) self . subscription = self . create_subscription ( String , 'chatter' , self . listener_callback , 10 ) self . subscription # prevent unused variable warning def listener_callback ( self , msg ): self . get_logger () . info ( 'I heard msg: \" %s \"' % msg . data ) def main ( args = None ): rclpy . init ( args = args ) minimal_subscriber = MinimalSubscriber () rclpy . spin ( minimal_subscriber ) # Destroy the node explicitly # (optional - otherwise it will be done automatically # when the garbage collector destroys the node object) minimal_subscriber . destroy_node () rclpy . shutdown () if __name__ == '__main__' : main () Add a new entry point in the setup.py file: 'listener = ros2_course.listener:main' , Build and run both nodes: cd ~/ros2_ws colcon build --symlink-install ros2 run ros2_course talker ros2 run ros2_course listener Use rqt_gui to display the nodes and topics of the running system: ros2 run rqt_gui rqt_gui","title":"5: Implementing a Subscriber in Python"},{"location":"02_linux_ros_principles/#useful-links","text":"ROS 2 Tutorials What is a ROS 2 package?","title":"Useful links"},{"location":"03_python_principles/","text":"03. Python principles, ROS Publisher, ROS Subscriber Lecture Python principles Interpreted, high-level programming language Name tribute to the comedy group Monty Python Powerful, still easy to learn, easy to use Readability Whitespace indentation Dynamically-typed Garbage colector and reference counting Object oriented programming Used in: AI, web applications, scientific computing, and many other areas python3 Python syntax import numpy as np import math class A : def __init__ ( self , name ): self . name = name def do_something ( self ): # will do something print ( self . name + \" is doing something.\" ) def count_to ( self , n ): # count to n, tell if the number is odd or even for i in range ( n ): if i % 2 == 0 : print ( i + \", it's even.\" ) else : print ( i + \", it's odd.\" ) if __name__ == \"__main__\" : a = A ( \"John\" ) a . do_something () a . count_to ( 10 ) Practice 1: Move the turtle in a straight line Let's write a ROS node that moves the turtle forward along a straight line for a given distance. Let's open a terminal. Let's create ~/ros2_ws/src/ros2_course/ros2_course the turtlesim_controller.py file in our directory: cd ros2_ws/src/ros2_course/ros2_course touch turtlesim_controller.py Add a new entry point in the setup.py file: 'turtlesim_controller = ros2_course.turtlesim_controller:main' , Copy the skeleton of the program into turtlesim_controller.py : import math import rclpy from rclpy.node import Node class TurtlesimController ( Node ): def __init__ ( self ): super () . __init__ ( 'turtlesim_controller' ) def go_straight ( self , speed , distance ): # Implement straght motion here def main ( args = None ): rclpy . init ( args = args ) tc = TurtlesimController () # Destroy the node explicitly # (optional - otherwise it will be done automatically # when the garbage collector destroys the node object) tc . destroy_node () rclpy . shutdown () if __name__ == '__main__' : main () Let's start a turtlesim_node and then examine the topic, with which we can control. In two separate terminal windows: ros2 run turtlesim turtlesim_node ros2 topic list ros2 topic info /turtle1/cmd_vel ros2 interface show geometry_msgs/msg/Twist Or use rqt_gui : ros2 run rqt_gui rqt_gui Import the message type geometry_msgs/msg/Twist and create the publisher in turtlesim_controller.py : from geometry_msgs.msg import Twist #... # In the constructor: self . twist_pub = self . create_publisher ( Twist , '/turtle1/cmd_vel' , 10 ) We implement the go_straight method. Let's calculate how long it takes, so that the turtle covers the given distance at the given speed. Publish a message with which we set the speed, then wait for the calculated time, after that send another message to reset the speed. A little help for using the API: # Create and publish msg vel_msg = Twist () if distance > 0 : vel_msg . linear . x = speed else : vel_msg . linear . x = - speed vel_msg . linear . y = 0.0 vel_msg . linear . z = 0.0 vel_msg . angular . x = 0.0 vel_msg . angular . y = 0.0 vel_msg . angular . z = 0.0 # Set loop rate loop_rate = self . create_rate ( 100 , self . get_clock ()) # Hz # Calculate time # T = ... # Publish first msg and note time when to stop self . twist_pub . publish ( vel_msg ) # self.get_logger().info('Turtle started.') when = self . get_clock () . now () + rclpy . time . Duration ( seconds = T ) # Publish msg while the calculated time is up while ( some condition ... ) and rclpy . ok (): self . twist_pub . publish ( vel_msg ) # self.get_logger().info('On its way...') rclpy . spin_once ( self ) # loop rate # turtle arrived, set velocity to 0 vel_msg . linear . x = 0.0 self . twist_pub . publish ( vel_msg ) # self.get_logger().info('Arrived to destination.') Build and run the node: cd ros2_ws colcon build --symlink-install ros2 run ros2_course turtlesim_controller 2: Draw shapes Let's implement the method for turning with a given angle a in turtlesim_controller.py , similar to straight motion. def turn ( self , omega , angle ): # Implement rotation here Let's implement the straight movement method of drawing a square with a turtle and using the methods that perform the turn. def draw_square ( self , speed , omega , a ): Let's implement the method of drawing any regular shape with a turtle using the methods that perform straight movement and turning. def draw_poly ( self , speed , omega , N , a ): 3: Go to function Let's examine the topic on which turtlesim_node publishes its current position. ros2 topic list ros2 topic info /turtle1/pose ros2 interface show turtlesim/msg/Pose Or use rqt_gui : ros2 run rqt_gui rqt_gui Let's define a subscriber for the topic and write the callback function. # Imports from turtlesim.msg import Pose # Constructor self . pose = None self . subscription = self . create_subscription ( Pose , '/turtle1/pose' , self . cb_pose , 10 ) # New method for TurtlesimController def cb_pose ( self , msg ): self . pose = msg We implement the go_to method. Let's test it, call it from main. # ... # Go to method def go_to ( self , speed , omega , x , y ): # Wait for position to be received loop_rate = self . create_rate ( 100 , self . get_clock ()) # Hz while self . pose is None and rclpy . ok (): self . get_logger () . info ( 'Waiting for pose...' ) rclpy . spin_once ( self ) # Stuff with atan2 # Main def main ( args = None ): rclpy . init ( args = args ) tc = TurtlesimController () tc . go_to ( 1.0 , 20.0 , 2 , 8 ) tc . go_to ( 1.0 , 20.0 , 2 , 2 ) tc . go_to ( 1.0 , 20.0 , 3 , 4 ) tc . go_to ( 1.0 , 20.0 , 6 , 2 ) # Destroy the node explicitly # (optional - otherwise it will be done automatically # when the garbage collector destroys the node object) tc . destroy_node () rclpy . shutdown () Extra: Advanced go to Write a go to function that uses a proportional controller. Useful links For loops in python Some python functions Turtlesim help atan2","title":"3. Python principles,  ROS Publisher, ROS Subscriber"},{"location":"03_python_principles/#03-python-principles-ros-publisher-ros-subscriber","text":"","title":"03. Python principles, ROS Publisher, ROS Subscriber"},{"location":"03_python_principles/#lecture","text":"","title":"Lecture"},{"location":"03_python_principles/#python-principles","text":"Interpreted, high-level programming language Name tribute to the comedy group Monty Python Powerful, still easy to learn, easy to use Readability Whitespace indentation Dynamically-typed Garbage colector and reference counting Object oriented programming Used in: AI, web applications, scientific computing, and many other areas python3","title":"Python principles"},{"location":"03_python_principles/#python-syntax","text":"import numpy as np import math class A : def __init__ ( self , name ): self . name = name def do_something ( self ): # will do something print ( self . name + \" is doing something.\" ) def count_to ( self , n ): # count to n, tell if the number is odd or even for i in range ( n ): if i % 2 == 0 : print ( i + \", it's even.\" ) else : print ( i + \", it's odd.\" ) if __name__ == \"__main__\" : a = A ( \"John\" ) a . do_something () a . count_to ( 10 )","title":"Python syntax"},{"location":"03_python_principles/#practice","text":"","title":"Practice"},{"location":"03_python_principles/#1-move-the-turtle-in-a-straight-line","text":"Let's write a ROS node that moves the turtle forward along a straight line for a given distance. Let's open a terminal. Let's create ~/ros2_ws/src/ros2_course/ros2_course the turtlesim_controller.py file in our directory: cd ros2_ws/src/ros2_course/ros2_course touch turtlesim_controller.py Add a new entry point in the setup.py file: 'turtlesim_controller = ros2_course.turtlesim_controller:main' , Copy the skeleton of the program into turtlesim_controller.py : import math import rclpy from rclpy.node import Node class TurtlesimController ( Node ): def __init__ ( self ): super () . __init__ ( 'turtlesim_controller' ) def go_straight ( self , speed , distance ): # Implement straght motion here def main ( args = None ): rclpy . init ( args = args ) tc = TurtlesimController () # Destroy the node explicitly # (optional - otherwise it will be done automatically # when the garbage collector destroys the node object) tc . destroy_node () rclpy . shutdown () if __name__ == '__main__' : main () Let's start a turtlesim_node and then examine the topic, with which we can control. In two separate terminal windows: ros2 run turtlesim turtlesim_node ros2 topic list ros2 topic info /turtle1/cmd_vel ros2 interface show geometry_msgs/msg/Twist Or use rqt_gui : ros2 run rqt_gui rqt_gui Import the message type geometry_msgs/msg/Twist and create the publisher in turtlesim_controller.py : from geometry_msgs.msg import Twist #... # In the constructor: self . twist_pub = self . create_publisher ( Twist , '/turtle1/cmd_vel' , 10 ) We implement the go_straight method. Let's calculate how long it takes, so that the turtle covers the given distance at the given speed. Publish a message with which we set the speed, then wait for the calculated time, after that send another message to reset the speed. A little help for using the API: # Create and publish msg vel_msg = Twist () if distance > 0 : vel_msg . linear . x = speed else : vel_msg . linear . x = - speed vel_msg . linear . y = 0.0 vel_msg . linear . z = 0.0 vel_msg . angular . x = 0.0 vel_msg . angular . y = 0.0 vel_msg . angular . z = 0.0 # Set loop rate loop_rate = self . create_rate ( 100 , self . get_clock ()) # Hz # Calculate time # T = ... # Publish first msg and note time when to stop self . twist_pub . publish ( vel_msg ) # self.get_logger().info('Turtle started.') when = self . get_clock () . now () + rclpy . time . Duration ( seconds = T ) # Publish msg while the calculated time is up while ( some condition ... ) and rclpy . ok (): self . twist_pub . publish ( vel_msg ) # self.get_logger().info('On its way...') rclpy . spin_once ( self ) # loop rate # turtle arrived, set velocity to 0 vel_msg . linear . x = 0.0 self . twist_pub . publish ( vel_msg ) # self.get_logger().info('Arrived to destination.') Build and run the node: cd ros2_ws colcon build --symlink-install ros2 run ros2_course turtlesim_controller","title":"1: Move the turtle in a straight line"},{"location":"03_python_principles/#2-draw-shapes","text":"Let's implement the method for turning with a given angle a in turtlesim_controller.py , similar to straight motion. def turn ( self , omega , angle ): # Implement rotation here Let's implement the straight movement method of drawing a square with a turtle and using the methods that perform the turn. def draw_square ( self , speed , omega , a ): Let's implement the method of drawing any regular shape with a turtle using the methods that perform straight movement and turning. def draw_poly ( self , speed , omega , N , a ):","title":"2: Draw shapes"},{"location":"03_python_principles/#3-go-to-function","text":"Let's examine the topic on which turtlesim_node publishes its current position. ros2 topic list ros2 topic info /turtle1/pose ros2 interface show turtlesim/msg/Pose Or use rqt_gui : ros2 run rqt_gui rqt_gui Let's define a subscriber for the topic and write the callback function. # Imports from turtlesim.msg import Pose # Constructor self . pose = None self . subscription = self . create_subscription ( Pose , '/turtle1/pose' , self . cb_pose , 10 ) # New method for TurtlesimController def cb_pose ( self , msg ): self . pose = msg We implement the go_to method. Let's test it, call it from main. # ... # Go to method def go_to ( self , speed , omega , x , y ): # Wait for position to be received loop_rate = self . create_rate ( 100 , self . get_clock ()) # Hz while self . pose is None and rclpy . ok (): self . get_logger () . info ( 'Waiting for pose...' ) rclpy . spin_once ( self ) # Stuff with atan2 # Main def main ( args = None ): rclpy . init ( args = args ) tc = TurtlesimController () tc . go_to ( 1.0 , 20.0 , 2 , 8 ) tc . go_to ( 1.0 , 20.0 , 2 , 2 ) tc . go_to ( 1.0 , 20.0 , 3 , 4 ) tc . go_to ( 1.0 , 20.0 , 6 , 2 ) # Destroy the node explicitly # (optional - otherwise it will be done automatically # when the garbage collector destroys the node object) tc . destroy_node () rclpy . shutdown ()","title":"3: Go to function"},{"location":"03_python_principles/#extra-advanced-go-to","text":"Write a go to function that uses a proportional controller.","title":"Extra: Advanced go to"},{"location":"03_python_principles/#useful-links","text":"For loops in python Some python functions Turtlesim help atan2","title":"Useful links"},{"location":"04_roslaunch/","text":"04. ROS 2 Launch, Param, Bag Lecture ROS 2 Launch Launch multiple nodes Set arguments Monitor running nodes React on changes in the state of nodes Python, XML and YAML file formats Usage ros2 launch package_name file.launch ros2 launch irob_robot dvrk_server.launch arm_typ: = PSM1 ROS 2 Parameters Configure nodes at startup or during runtime without changing the code Associated with individual nodes Consists of: key, value, descriptor Available data types: bool, int64, float64, string, byte[], bool[], int64[], float64[] or string[]. Useful command: ros2 param ROS 2 Bag Record and playback ROS topics Command line tool API for C++ and Python ros2 bag record -o <file_name> <topic_name> ros2 bag record --all ros2 bag info <filename.bag> ros2 bag play <filename.bag> Practice 1: Launch Turtlesim Mimic Create the launch folder inside the ros2_course package, where the launch files can be stored: cd ~/ros2_ws/src/ros2_course mkdir launch Create the turtlesim_mimic_launch.py file in the new launch folder a with the following content: from launch import LaunchDescription from launch_ros.actions import Node def generate_launch_description (): return LaunchDescription ([ Node ( package = 'turtlesim' , namespace = 'turtlesim1' , executable = 'turtlesim_node' , name = 'sim' ), Node ( package = 'turtlesim' , namespace = 'turtlesim2' , executable = 'turtlesim_node' , name = 'sim' ), Node ( package = 'turtlesim' , executable = 'mimic' , name = 'mimic' , remappings = [ ( '/input/pose' , '/turtlesim1/turtle1/pose' ), ( '/output/cmd_vel' , '/turtlesim2/turtle1/cmd_vel' ), ] ) ]) Add the followings to the setup.py file: import os from glob import glob # ... data_files =[ ( 'share/ament_index/resource_index/packages' , [ 'resource/' + package_name ]) , ( 'share/' + package_name, [ 'package.xml' ]) , # Include all launch files. ( os.path.join ( 'share' , package_name ) , glob ( 'launch/*launch.[pxy][yma]*' )) ] , Add the ros2launch dependency to the package.xml file: <exec_depend>ros2launch</exec_depend> Build the workspace: cd ros2_ws colcon build --symlink-install Launch the launch file: ros2 launch ros2_course turtlesim_mimic_launch.py Publish to the topic from the command line, in a new terminal window: ros2 topic pub -r 1 /turtlesim1/turtle1/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: 2.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: -1.8}}\" Let's examine the operation of the system using rqt_gui : ros2 run rqt_gui rqt_gui 2: Launch Turtlesim Goto Let's make a copy of turtlesim_mimic_launch.py from a file named turtlesim_controller_launch.py . Add the turtlesim_controller node written in the previous lesson to the launch file. The turtle to be controlled can be set using namespace or remappings . Build the workspace: cd ros2_ws colcon build --symlink-install launch the new launch file: ros2 launch ros2_course turtlesim_controller_launch.py 3: Turtlesim controller params Modify turtlesim_controller so that the linear velocity and angular velocity. is adjustable via ROS parameters. API example for parameters: import rclpy import rclpy.node class MinimalParam ( rclpy . node . Node ): def __init__ ( self ): super () . __init__ ( 'minimal_param_node' ) # Declare parameter named 'my_parameter' and # set default value to 'world' self . declare_parameter ( 'my_parameter' , 'world' ) self . timer = self . create_timer ( 1 , self . timer_callback ) def timer_callback ( self ): my_param = self . get_parameter ( 'my_parameter' ) . get_parameter_value () . string_value self . get_logger () . info ( 'Hello %s !' % my_param ) def main (): rclpy . init () node = MinimalParam () rclpy . spin ( node ) if __name__ == '__main__' : main () Let's run turtlesim_controller.py using the previously written launch file. Let's list the parameters. ros2 launch ros2_course turtlesim_controller_launch.py ros2 param list Change the speed and angular velocity parameters from the command line using the following command: ros2 param set <NODE_NAME> <PARAM_NAME> <NEW_VALUE> ros2 param set controller speed 100 .0 4: Turtlesim controller launch and substitutions Let's make a copy of turtlesim_controller_launch.py as turtlesim_controller_param_launch.py . Modify the new launch file based on the example below so that the velocity and angular velocity parameters of the launch can be specified as file arguments. from launch_ros.actions import Node from launch import LaunchDescription from launch.actions import DeclareLaunchArgument , ExecuteProcess , TimerAction from launch.conditions import IfCondition from launch.substitutions import LaunchConfiguration , PythonExpression def generate_launch_description (): turtlesim_ns_value = LaunchConfiguration ( 'turtlesim_ns' ) use_provided_red_value = LaunchConfiguration ( 'use_provided_red' ) new_background_r_value = LaunchConfiguration ( 'new_background_r' ) background_g_value = LaunchConfiguration ( 'background_g' ) background_b_value = LaunchConfiguration ( 'background_b' ) turtlesim_ns_launch_arg = DeclareLaunchArgument ( 'turtlesim_ns' , default_value = 'turtlesim1' , description = 'Namespace for turtle 1' ) use_provided_red_launch_arg = DeclareLaunchArgument ( 'use_provided_red' , default_value = 'False' ) new_background_r_launch_arg = DeclareLaunchArgument ( 'new_background_r' , default_value = '200' ) background_g_launch_arg = DeclareLaunchArgument ( 'background_g' , default_value = '100' ) background_b_launch_arg = DeclareLaunchArgument ( 'background_b' , default_value = '100' ) turtlesim_node = Node ( package = 'turtlesim' , namespace = turtlesim_ns_value , executable = 'turtlesim_node' , name = 'sim' , parameters = [{ 'background_g' : background_g_value , 'background_b' : background_b_value , }] ) spawn_turtle = ExecuteProcess ( cmd = [[ 'ros2 service call ' , turtlesim_ns , '/spawn ' , 'turtlesim/srv/Spawn ' , '\"{x: 2, y: 2, theta: 0.2}\"' ]], shell = True ) change_background_r = ExecuteProcess ( cmd = [[ 'ros2 param set ' , turtlesim_ns , '/sim background_r ' , '120' ]], shell = True ) change_background_r_conditioned = ExecuteProcess ( condition = IfCondition ( PythonExpression ([ new_background_r_value , ' == 200' , ' and ' , use_provided_red ]) ), cmd = [[ 'ros2 param set ' , turtlesim_ns_value , '/sim background_r ' , new_background_r ]], shell = True ) return LaunchDescription ([ turtlesim_ns_launch_arg , use_provided_red_launch_arg , new_background_r_launch_arg , turtlesim_node , spawn_turtle , change_background_r , TimerAction ( period = 2.0 , actions = [ change_background_r_conditioned ], ) ]) Build the workspace and run turtlesim_controller_param_launch.py : cd ros2_ws colcon build --symlink-install ros2 launch ros2_course turtlesim_controller_param_launch.py Let's list the arguments of the new launch file: ros2 launch ros2_course turtlesim_controller_param_launch.py --show-args Run the launch file by setting the arguments: ros2 launch ros2_course turtlesim_controller_param_launch.py speed: = 100 .0 omega: = 60 .0 5. Using the above example, let's set the background color also using command line argument(s). 5: Rosbag While the program implemented in the previous exercise is running, record the contents of the topics in a rosbag file. ros2 bag record --all Syntax The filename and the topics to record can also be set, e.g.: ros2 bag record -o turtle_bagfile_1 /turtle1/cmd_vel /turtle1/pose Use the following command to query the properties of the bag file: ros2 bag info <PATH_TO_BAGFILE> Play back the bag file and plot the pose/x value of one of the turtles on a graph using rqt_gui . ros2 bag info <PATH_TO_BAGFILE> ros2 run rqt_gui rqt_gui Useful links ROS 2 Launch Tutorial ROS 2 Parameters Using ROS 2 parameters in a Class ROS 2 Bag","title":"4. ROS 2 Launch, Param, Bag"},{"location":"04_roslaunch/#04-ros-2-launch-param-bag","text":"","title":"04. ROS 2 Launch, Param, Bag"},{"location":"04_roslaunch/#lecture","text":"","title":"Lecture"},{"location":"04_roslaunch/#ros-2-launch","text":"Launch multiple nodes Set arguments Monitor running nodes React on changes in the state of nodes Python, XML and YAML file formats","title":"ROS 2 Launch"},{"location":"04_roslaunch/#usage","text":"ros2 launch package_name file.launch ros2 launch irob_robot dvrk_server.launch arm_typ: = PSM1","title":"Usage"},{"location":"04_roslaunch/#ros-2-parameters","text":"Configure nodes at startup or during runtime without changing the code Associated with individual nodes Consists of: key, value, descriptor Available data types: bool, int64, float64, string, byte[], bool[], int64[], float64[] or string[]. Useful command: ros2 param","title":"ROS 2 Parameters"},{"location":"04_roslaunch/#ros-2-bag","text":"Record and playback ROS topics Command line tool API for C++ and Python ros2 bag record -o <file_name> <topic_name> ros2 bag record --all ros2 bag info <filename.bag> ros2 bag play <filename.bag>","title":"ROS 2 Bag"},{"location":"04_roslaunch/#practice","text":"","title":"Practice"},{"location":"04_roslaunch/#1-launch-turtlesim-mimic","text":"Create the launch folder inside the ros2_course package, where the launch files can be stored: cd ~/ros2_ws/src/ros2_course mkdir launch Create the turtlesim_mimic_launch.py file in the new launch folder a with the following content: from launch import LaunchDescription from launch_ros.actions import Node def generate_launch_description (): return LaunchDescription ([ Node ( package = 'turtlesim' , namespace = 'turtlesim1' , executable = 'turtlesim_node' , name = 'sim' ), Node ( package = 'turtlesim' , namespace = 'turtlesim2' , executable = 'turtlesim_node' , name = 'sim' ), Node ( package = 'turtlesim' , executable = 'mimic' , name = 'mimic' , remappings = [ ( '/input/pose' , '/turtlesim1/turtle1/pose' ), ( '/output/cmd_vel' , '/turtlesim2/turtle1/cmd_vel' ), ] ) ]) Add the followings to the setup.py file: import os from glob import glob # ... data_files =[ ( 'share/ament_index/resource_index/packages' , [ 'resource/' + package_name ]) , ( 'share/' + package_name, [ 'package.xml' ]) , # Include all launch files. ( os.path.join ( 'share' , package_name ) , glob ( 'launch/*launch.[pxy][yma]*' )) ] , Add the ros2launch dependency to the package.xml file: <exec_depend>ros2launch</exec_depend> Build the workspace: cd ros2_ws colcon build --symlink-install Launch the launch file: ros2 launch ros2_course turtlesim_mimic_launch.py Publish to the topic from the command line, in a new terminal window: ros2 topic pub -r 1 /turtlesim1/turtle1/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: 2.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: -1.8}}\" Let's examine the operation of the system using rqt_gui : ros2 run rqt_gui rqt_gui","title":"1: Launch Turtlesim Mimic"},{"location":"04_roslaunch/#2-launch-turtlesim-goto","text":"Let's make a copy of turtlesim_mimic_launch.py from a file named turtlesim_controller_launch.py . Add the turtlesim_controller node written in the previous lesson to the launch file. The turtle to be controlled can be set using namespace or remappings . Build the workspace: cd ros2_ws colcon build --symlink-install launch the new launch file: ros2 launch ros2_course turtlesim_controller_launch.py","title":"2: Launch Turtlesim Goto"},{"location":"04_roslaunch/#3-turtlesim-controller-params","text":"Modify turtlesim_controller so that the linear velocity and angular velocity. is adjustable via ROS parameters. API example for parameters: import rclpy import rclpy.node class MinimalParam ( rclpy . node . Node ): def __init__ ( self ): super () . __init__ ( 'minimal_param_node' ) # Declare parameter named 'my_parameter' and # set default value to 'world' self . declare_parameter ( 'my_parameter' , 'world' ) self . timer = self . create_timer ( 1 , self . timer_callback ) def timer_callback ( self ): my_param = self . get_parameter ( 'my_parameter' ) . get_parameter_value () . string_value self . get_logger () . info ( 'Hello %s !' % my_param ) def main (): rclpy . init () node = MinimalParam () rclpy . spin ( node ) if __name__ == '__main__' : main () Let's run turtlesim_controller.py using the previously written launch file. Let's list the parameters. ros2 launch ros2_course turtlesim_controller_launch.py ros2 param list Change the speed and angular velocity parameters from the command line using the following command: ros2 param set <NODE_NAME> <PARAM_NAME> <NEW_VALUE> ros2 param set controller speed 100 .0","title":"3: Turtlesim controller params"},{"location":"04_roslaunch/#4-turtlesim-controller-launch-and-substitutions","text":"Let's make a copy of turtlesim_controller_launch.py as turtlesim_controller_param_launch.py . Modify the new launch file based on the example below so that the velocity and angular velocity parameters of the launch can be specified as file arguments. from launch_ros.actions import Node from launch import LaunchDescription from launch.actions import DeclareLaunchArgument , ExecuteProcess , TimerAction from launch.conditions import IfCondition from launch.substitutions import LaunchConfiguration , PythonExpression def generate_launch_description (): turtlesim_ns_value = LaunchConfiguration ( 'turtlesim_ns' ) use_provided_red_value = LaunchConfiguration ( 'use_provided_red' ) new_background_r_value = LaunchConfiguration ( 'new_background_r' ) background_g_value = LaunchConfiguration ( 'background_g' ) background_b_value = LaunchConfiguration ( 'background_b' ) turtlesim_ns_launch_arg = DeclareLaunchArgument ( 'turtlesim_ns' , default_value = 'turtlesim1' , description = 'Namespace for turtle 1' ) use_provided_red_launch_arg = DeclareLaunchArgument ( 'use_provided_red' , default_value = 'False' ) new_background_r_launch_arg = DeclareLaunchArgument ( 'new_background_r' , default_value = '200' ) background_g_launch_arg = DeclareLaunchArgument ( 'background_g' , default_value = '100' ) background_b_launch_arg = DeclareLaunchArgument ( 'background_b' , default_value = '100' ) turtlesim_node = Node ( package = 'turtlesim' , namespace = turtlesim_ns_value , executable = 'turtlesim_node' , name = 'sim' , parameters = [{ 'background_g' : background_g_value , 'background_b' : background_b_value , }] ) spawn_turtle = ExecuteProcess ( cmd = [[ 'ros2 service call ' , turtlesim_ns , '/spawn ' , 'turtlesim/srv/Spawn ' , '\"{x: 2, y: 2, theta: 0.2}\"' ]], shell = True ) change_background_r = ExecuteProcess ( cmd = [[ 'ros2 param set ' , turtlesim_ns , '/sim background_r ' , '120' ]], shell = True ) change_background_r_conditioned = ExecuteProcess ( condition = IfCondition ( PythonExpression ([ new_background_r_value , ' == 200' , ' and ' , use_provided_red ]) ), cmd = [[ 'ros2 param set ' , turtlesim_ns_value , '/sim background_r ' , new_background_r ]], shell = True ) return LaunchDescription ([ turtlesim_ns_launch_arg , use_provided_red_launch_arg , new_background_r_launch_arg , turtlesim_node , spawn_turtle , change_background_r , TimerAction ( period = 2.0 , actions = [ change_background_r_conditioned ], ) ]) Build the workspace and run turtlesim_controller_param_launch.py : cd ros2_ws colcon build --symlink-install ros2 launch ros2_course turtlesim_controller_param_launch.py Let's list the arguments of the new launch file: ros2 launch ros2_course turtlesim_controller_param_launch.py --show-args Run the launch file by setting the arguments: ros2 launch ros2_course turtlesim_controller_param_launch.py speed: = 100 .0 omega: = 60 .0","title":"4: Turtlesim controller launch and substitutions"},{"location":"04_roslaunch/#5-using-the-above-example-lets-set-the-background-color-also-using-command-line-arguments","text":"","title":"5. Using the above example, let's set the background color also using command line argument(s)."},{"location":"04_roslaunch/#5-rosbag","text":"While the program implemented in the previous exercise is running, record the contents of the topics in a rosbag file. ros2 bag record --all Syntax The filename and the topics to record can also be set, e.g.: ros2 bag record -o turtle_bagfile_1 /turtle1/cmd_vel /turtle1/pose Use the following command to query the properties of the bag file: ros2 bag info <PATH_TO_BAGFILE> Play back the bag file and plot the pose/x value of one of the turtles on a graph using rqt_gui . ros2 bag info <PATH_TO_BAGFILE> ros2 run rqt_gui rqt_gui","title":"5: Rosbag"},{"location":"04_roslaunch/#useful-links","text":"ROS 2 Launch Tutorial ROS 2 Parameters Using ROS 2 parameters in a Class ROS 2 Bag","title":"Useful links"},{"location":"05_git/","text":"05. VCS, Git Lecture Version control, Git Track changes in a set of files Coordinating work among developers Who made what changes and when Revert back at any time Local and remote repos Take snapshots of files by making a commit Install sudo apt install git Basic commands git init # Initialize local git repo git add <file> # Add file/files to staging area git status # Check status of working tree and staging area git commit -m \"What I've done\" # Commit changes in index git push # Push to remote repository git pull # Pull latest changes from remote repo git branch <new_branch_name> git checkout <branch_name> git merge <branch_name> # Merge the branch into the current branch git config --global user.name \"Istvan Szabo\" git config --global user.email \"istvan.szabo@gmail.com\" GitHub git remote git clone <link> # Copy repo into a new directory # Add remote to repository: git remote add origin <link> git push -u origin master Some alternatives to GitHub GitLab, BitBucket, Launchpad, Phabricator Markdown Markup language, easy to read Text file \u2192 Formatted document Widespread usag, e.g., blogs, forums, documentations, readme files, GitHub Markdown Cheatsheet Practice 0: Create a GitHub repo Register to GitHub, then create a token. Create a private repo on GitHub for the ros2_course package. Tip Store personal token: git config --global credential.helper store Create the local repo, set up remote, then push the package contents to GitHUb (GitHub will also help after the repo is created): cd ~/ros2_ws/src/ros2_course git init git add . git commit -m \"Initial commit\" git branch -M main git remote add origin <REPO_GITHUB_ADDRESS>.git git push -u origin main Add a README.md to the ros2_course package with the following content: # ros2_course ## About Something about the package. ## Usage How to *build* and use the package. cd ~/ros2_ws colcon build --symlink-install Commit and push changes: git add . git commit -m \"Add README\" git push VCS in Clion The use of GitHub can also be configured in CLion, so you can manage versions in a graphical interface. Tip Windows and Linux clock problem: timedatectl set-local-rtc 1 --adjust-system-clock Useful links Markdown Cheatsheet","title":"5. Versioning, Git"},{"location":"05_git/#05-vcs-git","text":"","title":"05. VCS, Git"},{"location":"05_git/#lecture","text":"","title":"Lecture"},{"location":"05_git/#version-control-git","text":"Track changes in a set of files Coordinating work among developers Who made what changes and when Revert back at any time Local and remote repos Take snapshots of files by making a commit","title":"Version control, Git"},{"location":"05_git/#install","text":"sudo apt install git","title":"Install"},{"location":"05_git/#basic-commands","text":"git init # Initialize local git repo git add <file> # Add file/files to staging area git status # Check status of working tree and staging area git commit -m \"What I've done\" # Commit changes in index git push # Push to remote repository git pull # Pull latest changes from remote repo git branch <new_branch_name> git checkout <branch_name> git merge <branch_name> # Merge the branch into the current branch git config --global user.name \"Istvan Szabo\" git config --global user.email \"istvan.szabo@gmail.com\"","title":"Basic commands"},{"location":"05_git/#github","text":"git remote git clone <link> # Copy repo into a new directory # Add remote to repository: git remote add origin <link> git push -u origin master Some alternatives to GitHub GitLab, BitBucket, Launchpad, Phabricator","title":"GitHub"},{"location":"05_git/#markdown","text":"Markup language, easy to read Text file \u2192 Formatted document Widespread usag, e.g., blogs, forums, documentations, readme files, GitHub Markdown Cheatsheet","title":"Markdown"},{"location":"05_git/#practice","text":"","title":"Practice"},{"location":"05_git/#0-create-a-github-repo","text":"Register to GitHub, then create a token. Create a private repo on GitHub for the ros2_course package. Tip Store personal token: git config --global credential.helper store Create the local repo, set up remote, then push the package contents to GitHUb (GitHub will also help after the repo is created): cd ~/ros2_ws/src/ros2_course git init git add . git commit -m \"Initial commit\" git branch -M main git remote add origin <REPO_GITHUB_ADDRESS>.git git push -u origin main Add a README.md to the ros2_course package with the following content: # ros2_course ## About Something about the package. ## Usage How to *build* and use the package. cd ~/ros2_ws colcon build --symlink-install Commit and push changes: git add . git commit -m \"Add README\" git push VCS in Clion The use of GitHub can also be configured in CLion, so you can manage versions in a graphical interface. Tip Windows and Linux clock problem: timedatectl set-local-rtc 1 --adjust-system-clock","title":"0: Create a GitHub repo"},{"location":"05_git/#useful-links","text":"Markdown Cheatsheet","title":"Useful links"},{"location":"06_da_vinci/","text":"06. Principles of robotics, programming a da Vinci surgical robot in a simulated environment Rigid body motion Def. Rigid body A rigid body is defined as a body on which the distance between two points remains constant in time regardless of the force applied on it. Shape and the volume of the rigid bodies are also constant. The pose of a rigid body can be given by the three coordinates of three of its points that do not lie on the same straight line. The pose of a rigid body can be described in a more expressive way by the three coordinates of one of its points chosen arbitrarily position and the body's orientation . The motion of rigid bodies is composed by two elemental motions: translation and rotation . During translation , all points of the body move along straight, parallel lines. During rotation , the position of the points of the rotational axis are constant, and the other points of the body move along circles in planes perpendicular to the axis of rotation. The free motion of rigid bodies can always be expressed as the superposition of a translational motion and a rotation around a single axis. 3D transformations Position: 3D offset vector Orientation: 3 x 3 rotation matrix further orientation representations: Euler-angles, RPY, angle axis, quaternion Pose : 4 \u00d7 4 (homogenous) transformation matrix Frame : origin, 3 axes, 3 base vectors, right hand rule Homogenous transformation: rotation and translation in one transfromation e.g., for the rotation \\(\\mathbf{R}\\) and translation \\(\\mathbf{v}\\) : \\[ \\mathbf{T} = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right] = \\left[\\matrix{r_{1,1} & r_{1,2} & r_{1,3} & v_x\\\\r_{2,1} & r_{2,2} & r_{2,3} & v_y\\\\r_{3,1} & r_{3,2} & r_{3,3} & v_z\\\\\\ 0 & 0 & 0 & 1 }\\right] \\] Homogenous coordinates: Vector: extended with 0, \\(\\mathbf{a_H}=\\left[\\matrix{\\mathbf{a} \\\\ 0}\\right]=\\left[\\matrix{a_x \\\\ a_y \\\\ a_z \\\\ 0}\\right]\\) Point: extended by 1, \\(\\mathbf{p_H}=\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right]=\\left[\\matrix{p_x \\\\ p_y \\\\ p_z \\\\ 1}\\right]\\) Applying transfomrations is much easier: \\[ \\mathbf{q} = \\mathbf{R}\\mathbf{p} + \\mathbf{v} \\to \\left[\\matrix{\\mathbf{q} \\\\ 1}\\right] = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right]\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right] \\] Degrees of Freedom (DoF): the number of independent parameters. Principles of robotics Robots are built of: segments (or links) \u00e9s joints Task space (or cartesian space): 3D space around us, where the task, endpoint trajectories, obstacles are defined. TCP (Tool Center Point): Frame fixed to the end effector of the robot. Base frame , world frame Joint space : Properties or values regarding the joints. Low-level controller. Joint angles, joint velocities, accelerations, torques.... Python libraries Numpy Python library High dimension arrays and matrices Mathematical functions import numpy as np # Creating ndarrays a = np . zeros ( 3 ) a . shape a . shape = ( 3 , 1 ) a = np . ones ( 5 ) a = np . empty ( 10 ) l = np . linspace ( 5 , 10 , 6 ) r = np . array ([ 1 , 2 ]) # ndarray from python list r = np . array ([[ 1 , 2 ],[ 3 , 4 ]]) type ( r ) # Indexing l [ 0 ] l [ 0 : 2 ] l [ - 1 ] r [:, 0 ] # Operations on ndarrays r_sin = np . sin ( r ) np . max ( r ) np . min ( r ) np . sum ( r ) np . mean ( r ) np . std ( r ) l < 7 l [ l < 7 ] np . where ( l < 7 ) p = np . linspace ( 1 , 5 , 6 ) q = np . linspace ( 10 , 14 , 6 ) s = p + q s = p * q s = p * 10 s = p + 10 s = p @ q # dot product s = r . T If not installed: pip3 install numpy Matplotlib Visualization in python Syntax similar to Matlab import numpy as np from matplotlib import pyplot as plt X = np . linspace ( - np . pi , np . pi , 256 ) C , S = np . cos ( X ), np . sin ( X ) plt . plot ( X , C ) plt . plot ( X , S ) plt . show () If not installed: pip3 install matplotlib Practice 1: dVRK ROS2 install On Ubuntu 20.04 you will need the following packages: sudo apt install python3-vcstool python3-colcon-common-extensions python3-pykdl libxml2-dev libraw1394-dev libncurses5-dev qtcreator swig sox espeak cmake-curses-gui cmake-qt-gui git subversion gfortran libcppunit-dev libqt5xmlpatterns5-dev libbluetooth-dev ros-foxy-joint-state-publisher* ros-foxy-xacro Clone the dVRK ROS2 packages with vcs , then build: cd ~/ros2_ws/src vcs import --input https://raw.githubusercontent.com/jhu-dvrk/dvrk_robot_ros2/main/dvrk.vcs --recursive cd ~/ros2_ws colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release source ~/ros2_ws/install/setup.bash Start the RViz simulation of PSM1 (Patient Side Manipulator). Do not forget to HOME on the dVRK console. Study the simulator operation using the learned prancs ( ros2 topic list , ros2 topic echo ros2 run rqt_gui rqt_gui , etc.). # dVRK main console ros2 run dvrk_robot dvrk_console_json -j ~/ros2_ws/install/sawIntuitiveResearchKitAll/share/sawIntuitiveResearchKit/share/console/console-PSM1_KIN_SIMULATED.json # ROS 2 joint and robot state publishers ros2 launch dvrk_model dvrk_state_publisher.launch.py arm: = PSM1 # RViz ros2 run rviz2 rviz2 -d ~/ros2_ws/install/dvrk_model/share/dvrk_model/rviz/PSM1.rviz ros2 run rqt_gui rqt_gui For URDF related errors locale # check for UTF-8 sudo apt update && sudo apt install locales sudo locale-gen en_US en_US.UTF-8 sudo update-locale LC_ALL = en_US.UTF-8 LANG = en_US.UTF-8 export LANG = en_US.UTF-8 locale # verify settings 2: PSM subscriber Create a new python source file named psm_grasp.py in ~/ros2_ws/src/ros2_course/ros2_course . Specify the new entry point in setup.py in the usual way. Subscribe to topics that publish the TCP (Tool Center Point) position of the PSM and the angle of the jaws of the tweezers. /PSM1/measured_cp /PSM1/jaw/measured_js Build and run the node: source ros_setup.sh -v 2 cd ~/ros2_ws colcon build --symlink-install ros2 run ros2_course psm_grasp 3. Moving PSM TCP along a linear trajectory The PSM expects the desired TCP position and the angle closed by the jaws of the clamp in the topics below. Create publishers in psm_grasp.py for these topics. /PSM1/servo_cp /PSM1/jaw/servo_jp Write a function that moves the TCP along a linear trajectory to the desired position. Send the pin to position (0.0, 0.05, -0.12), leave the orientation unchanged. The sampling time should be 0.01s. Using Matplotlib plot the planned trajectory x, y and z components of the projected trajectory as a function of time. def move_tcp_to ( self , target , v , dt ): Write a function to open and close the gripper, also using a linear trajectory. def move_jaw_to ( self , target , omega , dt ): 4. Dummy marker Create a new python source file named dummy_marker.py . Specify the entry point in setup.py in the usual way. Implement a python program that publishes a marker with position (-0.05, 0.08, -0.14) in topic dummy_target_marker . The value of the frame_id add tag should be PSM1_psm_base_link . Copy the following code into the file dummy_marker.py : import rclpy from rclpy.node import Node from visualization_msgs.msg import Marker class DummyMarker ( Node ): def __init__ ( self , position ): super () . __init__ ( 'minimal_publisher' ) self . position = position self . publisher_ = self . create_publisher ( Marker , 'dummy_target_marker' , 10 ) timer_period = 0.1 # seconds self . timer = self . create_timer ( timer_period , self . timer_callback ) self . i = 0 i = 0 def timer_callback ( self ): marker = Marker () marker . header . frame_id = 'PSM1_psm_base_link' marker . header . stamp = self . get_clock () . now () . to_msg () marker . ns = \"dvrk_viz\" marker . id = self . i marker . type = Marker . SPHERE marker . action = Marker . MODIFY marker . pose . position . x = self . position [ 0 ] marker . pose . position . y = self . position [ 1 ] marker . pose . position . z = self . position [ 2 ] marker . pose . orientation . x = 0.0 marker . pose . orientation . y = 0.0 marker . pose . orientation . z = 0.0 marker . pose . orientation . w = 1.0 marker . scale . x = 0.008 marker . scale . y = 0.008 marker . scale . z = 0.008 marker . color . a = 1.0 # Don't forget to set the alpha! marker . color . r = 0.0 marker . color . g = 1.0 marker . color . b = 0.0 ; self . publisher_ . publish ( marker ) self . i += 1 def main ( args = None ): rclpy . init ( args = args ) marker_publisher = DummyMarker ([ - 0.05 , 0.08 , - 0.12 ]) rclpy . spin ( marker_publisher ) # Destroy the node explicitly # (optional - otherwise it will be done automatically # when the garbage collector destroys the node object) marker_publisher . destroy_node () rclpy . shutdown () if __name__ == '__main__' : main () Run the node and display the marker in RViz. 5. Grasping the marker Subscribe to the topic sending the marker position in psm_grasp.py . Modify psm_grasp.py to use the tweezers to grasp the generated marker. !!! note The simulator used has a tendency for certain values to get \"stuck\", so it is a good idea to reset the lever at the beginning of the program using the following lines: #Reset the arm psm . move_tcp_to ([ 0.0 , 0.0 , - 0.12 ], 0.01 , 0.01 ) psm . move_jaw_to ( 0.0 , 0.1 , 0.01 ) Useful links Build dVRK2 on ROS2 Marker examples Numpy vector magnitude Numpy linspace","title":"6. Principles of robotics, da Vinci"},{"location":"06_da_vinci/#06-principles-of-robotics-programming-a-da-vinci-surgical-robot-in-a-simulated-environment","text":"","title":"06. Principles of robotics, programming a da Vinci surgical robot in a simulated environment"},{"location":"06_da_vinci/#rigid-body-motion","text":"Def. Rigid body A rigid body is defined as a body on which the distance between two points remains constant in time regardless of the force applied on it. Shape and the volume of the rigid bodies are also constant. The pose of a rigid body can be given by the three coordinates of three of its points that do not lie on the same straight line. The pose of a rigid body can be described in a more expressive way by the three coordinates of one of its points chosen arbitrarily position and the body's orientation . The motion of rigid bodies is composed by two elemental motions: translation and rotation . During translation , all points of the body move along straight, parallel lines. During rotation , the position of the points of the rotational axis are constant, and the other points of the body move along circles in planes perpendicular to the axis of rotation. The free motion of rigid bodies can always be expressed as the superposition of a translational motion and a rotation around a single axis.","title":"Rigid body motion"},{"location":"06_da_vinci/#3d-transformations","text":"Position: 3D offset vector Orientation: 3 x 3 rotation matrix further orientation representations: Euler-angles, RPY, angle axis, quaternion Pose : 4 \u00d7 4 (homogenous) transformation matrix Frame : origin, 3 axes, 3 base vectors, right hand rule Homogenous transformation: rotation and translation in one transfromation e.g., for the rotation \\(\\mathbf{R}\\) and translation \\(\\mathbf{v}\\) : \\[ \\mathbf{T} = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right] = \\left[\\matrix{r_{1,1} & r_{1,2} & r_{1,3} & v_x\\\\r_{2,1} & r_{2,2} & r_{2,3} & v_y\\\\r_{3,1} & r_{3,2} & r_{3,3} & v_z\\\\\\ 0 & 0 & 0 & 1 }\\right] \\] Homogenous coordinates: Vector: extended with 0, \\(\\mathbf{a_H}=\\left[\\matrix{\\mathbf{a} \\\\ 0}\\right]=\\left[\\matrix{a_x \\\\ a_y \\\\ a_z \\\\ 0}\\right]\\) Point: extended by 1, \\(\\mathbf{p_H}=\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right]=\\left[\\matrix{p_x \\\\ p_y \\\\ p_z \\\\ 1}\\right]\\) Applying transfomrations is much easier: \\[ \\mathbf{q} = \\mathbf{R}\\mathbf{p} + \\mathbf{v} \\to \\left[\\matrix{\\mathbf{q} \\\\ 1}\\right] = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right]\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right] \\] Degrees of Freedom (DoF): the number of independent parameters.","title":"3D transformations"},{"location":"06_da_vinci/#principles-of-robotics","text":"Robots are built of: segments (or links) \u00e9s joints Task space (or cartesian space): 3D space around us, where the task, endpoint trajectories, obstacles are defined. TCP (Tool Center Point): Frame fixed to the end effector of the robot. Base frame , world frame Joint space : Properties or values regarding the joints. Low-level controller. Joint angles, joint velocities, accelerations, torques....","title":"Principles of robotics"},{"location":"06_da_vinci/#python-libraries","text":"","title":"Python libraries"},{"location":"06_da_vinci/#numpy","text":"Python library High dimension arrays and matrices Mathematical functions import numpy as np # Creating ndarrays a = np . zeros ( 3 ) a . shape a . shape = ( 3 , 1 ) a = np . ones ( 5 ) a = np . empty ( 10 ) l = np . linspace ( 5 , 10 , 6 ) r = np . array ([ 1 , 2 ]) # ndarray from python list r = np . array ([[ 1 , 2 ],[ 3 , 4 ]]) type ( r ) # Indexing l [ 0 ] l [ 0 : 2 ] l [ - 1 ] r [:, 0 ] # Operations on ndarrays r_sin = np . sin ( r ) np . max ( r ) np . min ( r ) np . sum ( r ) np . mean ( r ) np . std ( r ) l < 7 l [ l < 7 ] np . where ( l < 7 ) p = np . linspace ( 1 , 5 , 6 ) q = np . linspace ( 10 , 14 , 6 ) s = p + q s = p * q s = p * 10 s = p + 10 s = p @ q # dot product s = r . T If not installed: pip3 install numpy","title":"Numpy"},{"location":"06_da_vinci/#matplotlib","text":"Visualization in python Syntax similar to Matlab import numpy as np from matplotlib import pyplot as plt X = np . linspace ( - np . pi , np . pi , 256 ) C , S = np . cos ( X ), np . sin ( X ) plt . plot ( X , C ) plt . plot ( X , S ) plt . show () If not installed: pip3 install matplotlib","title":"Matplotlib"},{"location":"06_da_vinci/#practice","text":"","title":"Practice"},{"location":"06_da_vinci/#1-dvrk-ros2-install","text":"On Ubuntu 20.04 you will need the following packages: sudo apt install python3-vcstool python3-colcon-common-extensions python3-pykdl libxml2-dev libraw1394-dev libncurses5-dev qtcreator swig sox espeak cmake-curses-gui cmake-qt-gui git subversion gfortran libcppunit-dev libqt5xmlpatterns5-dev libbluetooth-dev ros-foxy-joint-state-publisher* ros-foxy-xacro Clone the dVRK ROS2 packages with vcs , then build: cd ~/ros2_ws/src vcs import --input https://raw.githubusercontent.com/jhu-dvrk/dvrk_robot_ros2/main/dvrk.vcs --recursive cd ~/ros2_ws colcon build --symlink-install --cmake-args -DCMAKE_BUILD_TYPE = Release source ~/ros2_ws/install/setup.bash Start the RViz simulation of PSM1 (Patient Side Manipulator). Do not forget to HOME on the dVRK console. Study the simulator operation using the learned prancs ( ros2 topic list , ros2 topic echo ros2 run rqt_gui rqt_gui , etc.). # dVRK main console ros2 run dvrk_robot dvrk_console_json -j ~/ros2_ws/install/sawIntuitiveResearchKitAll/share/sawIntuitiveResearchKit/share/console/console-PSM1_KIN_SIMULATED.json # ROS 2 joint and robot state publishers ros2 launch dvrk_model dvrk_state_publisher.launch.py arm: = PSM1 # RViz ros2 run rviz2 rviz2 -d ~/ros2_ws/install/dvrk_model/share/dvrk_model/rviz/PSM1.rviz ros2 run rqt_gui rqt_gui For URDF related errors locale # check for UTF-8 sudo apt update && sudo apt install locales sudo locale-gen en_US en_US.UTF-8 sudo update-locale LC_ALL = en_US.UTF-8 LANG = en_US.UTF-8 export LANG = en_US.UTF-8 locale # verify settings","title":"1: dVRK ROS2 install"},{"location":"06_da_vinci/#2-psm-subscriber","text":"Create a new python source file named psm_grasp.py in ~/ros2_ws/src/ros2_course/ros2_course . Specify the new entry point in setup.py in the usual way. Subscribe to topics that publish the TCP (Tool Center Point) position of the PSM and the angle of the jaws of the tweezers. /PSM1/measured_cp /PSM1/jaw/measured_js Build and run the node: source ros_setup.sh -v 2 cd ~/ros2_ws colcon build --symlink-install ros2 run ros2_course psm_grasp","title":"2: PSM subscriber"},{"location":"06_da_vinci/#3-moving-psm-tcp-along-a-linear-trajectory","text":"The PSM expects the desired TCP position and the angle closed by the jaws of the clamp in the topics below. Create publishers in psm_grasp.py for these topics. /PSM1/servo_cp /PSM1/jaw/servo_jp Write a function that moves the TCP along a linear trajectory to the desired position. Send the pin to position (0.0, 0.05, -0.12), leave the orientation unchanged. The sampling time should be 0.01s. Using Matplotlib plot the planned trajectory x, y and z components of the projected trajectory as a function of time. def move_tcp_to ( self , target , v , dt ): Write a function to open and close the gripper, also using a linear trajectory. def move_jaw_to ( self , target , omega , dt ):","title":"3. Moving PSM TCP along a linear trajectory"},{"location":"06_da_vinci/#4-dummy-marker","text":"Create a new python source file named dummy_marker.py . Specify the entry point in setup.py in the usual way. Implement a python program that publishes a marker with position (-0.05, 0.08, -0.14) in topic dummy_target_marker . The value of the frame_id add tag should be PSM1_psm_base_link . Copy the following code into the file dummy_marker.py : import rclpy from rclpy.node import Node from visualization_msgs.msg import Marker class DummyMarker ( Node ): def __init__ ( self , position ): super () . __init__ ( 'minimal_publisher' ) self . position = position self . publisher_ = self . create_publisher ( Marker , 'dummy_target_marker' , 10 ) timer_period = 0.1 # seconds self . timer = self . create_timer ( timer_period , self . timer_callback ) self . i = 0 i = 0 def timer_callback ( self ): marker = Marker () marker . header . frame_id = 'PSM1_psm_base_link' marker . header . stamp = self . get_clock () . now () . to_msg () marker . ns = \"dvrk_viz\" marker . id = self . i marker . type = Marker . SPHERE marker . action = Marker . MODIFY marker . pose . position . x = self . position [ 0 ] marker . pose . position . y = self . position [ 1 ] marker . pose . position . z = self . position [ 2 ] marker . pose . orientation . x = 0.0 marker . pose . orientation . y = 0.0 marker . pose . orientation . z = 0.0 marker . pose . orientation . w = 1.0 marker . scale . x = 0.008 marker . scale . y = 0.008 marker . scale . z = 0.008 marker . color . a = 1.0 # Don't forget to set the alpha! marker . color . r = 0.0 marker . color . g = 1.0 marker . color . b = 0.0 ; self . publisher_ . publish ( marker ) self . i += 1 def main ( args = None ): rclpy . init ( args = args ) marker_publisher = DummyMarker ([ - 0.05 , 0.08 , - 0.12 ]) rclpy . spin ( marker_publisher ) # Destroy the node explicitly # (optional - otherwise it will be done automatically # when the garbage collector destroys the node object) marker_publisher . destroy_node () rclpy . shutdown () if __name__ == '__main__' : main () Run the node and display the marker in RViz.","title":"4. Dummy marker"},{"location":"06_da_vinci/#5-grasping-the-marker","text":"Subscribe to the topic sending the marker position in psm_grasp.py . Modify psm_grasp.py to use the tweezers to grasp the generated marker. !!! note The simulator used has a tendency for certain values to get \"stuck\", so it is a good idea to reset the lever at the beginning of the program using the following lines: #Reset the arm psm . move_tcp_to ([ 0.0 , 0.0 , - 0.12 ], 0.01 , 0.01 ) psm . move_jaw_to ( 0.0 , 0.1 , 0.01 )","title":"5. Grasping the marker"},{"location":"06_da_vinci/#useful-links","text":"Build dVRK2 on ROS2 Marker examples Numpy vector magnitude Numpy linspace","title":"Useful links"},{"location":"07_robotics_principles/","text":"07. Kinematics, inverse kinematics, Programming of a simulated robotic arm Repetition 3D transformations Position: 3 element offset vector Orientation: 3 x 3 rotation matrix additional orientation representations: Euler angles, RPY, angle axis, quaternion Pose (pose): 4 \u00d7 4 transformation matrix Coordinate system (frame): zero point, 3 axis, 3 base vector, right-hand rule Homogeneous transformations: rotation and translation together e.g. \\(\\mathbf{R}\\) for rotation and \\(\\mathbf{v}\\) for translation: \\[ \\mathbf{T} = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right] = \\left[\\matrix{r_{1,1} & r_{1,2} & r_{1,3} & v_x\\\\r_{2,1} & r_{2,2} & r_{2,3} & v_y\\\\r_{3,1} & r_{3,2} & r_{3,3} & v_z\\\\\\ 0 & 0 & 0 & 1 }\\right] \\] Homogeneous coordinates: Vector: add 0, \\(\\mathbf{a_H}=\\left[\\matrix{\\mathbf{a} \\\\ 0}\\right]=\\left[\\matrix{a_x \\\\ a_y \\\\ a_z \\\\ 0}\\right]\\) Point: add 1, \\(\\mathbf{p_H}=\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right]=\\left[\\matrix{p_x \\\\ p_y \\\\ p_z \\\\ 1}\\right]\\) Using transformations is simpler: \\[ \\mathbf{q} = \\mathbf{R}\\mathbf{p} + \\mathbf{v} \\to \\left[\\matrix{\\mathbf{q} \\\\ 1}\\right] = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right]\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right] \\] Degree of freedom (DoF): number of independent quantities. Robotics basics Robot structure: segments (link) and joints Task space (cartesian space): Three-dimensional space where the task, trajectories, obstacles, etc. are defined. TCP (Tool Center Point): coordinate frame fixed to the end effector Base/world frame Joint space : Quantities assigned to the robot's joints, which can be interpreted by the robot's low-level control system. Joint coordinates, velocities, accelerations, torques... Lecture Kinematics, inverse kinematics Kinematics Def. Kinematics Calculating the position of the TCP (or anything else) from the hinge coordinates. Kinematic model Denavit--Hartenberg (DH) convention URDF (Unified Robotics Description Format, XML-based) If the coordinate systems assigned to the segments are \\(base, 1, 2, 3, ..., TCP\\) , the transfomrms between adjacent segments \\(i\\) and \\(i+1\\) are \\(T_{i+1,i}(q_{i+1})\\) (which is a function of the angle of the joint between them), the transfomrms between the base frame and TCP can be written up (for a robot with \\(n\\) joints): \\[ T_{TCP,base}(q_1, \\cdots, q_n) = T_{TCP,n-1}(q_{n}) \\cdot T_{n-1,n-2}(q_{n-1}) \\cdots T_{2,1}(q_2) \\cdot T_{1,base}(q_1) \\cdot base \\] Inverse kinematics Def. Inverse kinematics Compute joint coordinates to achieve (desired) TCP (or any other) pose. Differential inverse kinematics Def. Differential inverse kinematics Which change in the wrist coordinates achieves the desired small change in the TCP pose (rotation and translation). Jacobi matrix (Jacobian): a matrix of first-order partial derivatives of a vector-valued function. \\[ \\mathbf{J} = \\left[\\matrix{\\frac{\\partial x_1}{\\partial q_1} & \\frac{\\partial x_1}{\\partial q_2} &\\frac{\\partial x_1}{\\partial q_3} & \\dots &\\frac{\\partial x_1}{\\partial q_n} \\\\ \\frac{\\partial x_2}{\\partial q_1} & \\frac{\\partial x_2}{\\partial q_2} &\\frac{\\partial x_2} {\\partial q_3} & \\dots &\\frac{\\partial x_2}{\\partial q_n} \\\\ \\frac{\\partial x_3}{\\partial q_1} & \\frac{\\partial x_3}{\\partial q_2} &\\frac{\\partial x_3}{\\partial q_3} & \\dots &\\frac{\\partial x_3}{\\partial q_n} \\\\ \\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\ \\frac{\\partial x_m}{\\partial q_1} & \\frac{\\partial x_m}{\\partial q_2} &\\frac{\\partial x_m}{\\partial q_3} & \\dots &\\frac{\\partial x_m}{\\partial q_n} \\\\}\\right] \\] Jacobi matrix significance in robotics : gives the relationship between joint velocities and TCP velocity. \\[ \\left[\\matrix{\\mathbf{v} \\\\ \\mathbf{\\omega}}\\right] =\\mathbf{J}(\\mathbf{q})\\cdot \\mathbf{\\dot{q}} \\] Inverse kinematics using Jacobian inverse Calculate the difference between the desired and the current position: \\(\\Delta\\mathbf{r} = \\mathbf{r}_{desired} - \\mathbf{r}_0\\) Calculate the difference in rotations: \\(\\Delta\\mathbf{R} = \\mathbf{R}_{desired}\\mathbf{R}_{0}^{T}\\) , then convert to axis angle representation \\((\\mathbf{t},\\phi)\\) Compute \\(\\Delta\\mathbf{ q}=\\mathbf{J}^{-1}(\\mathbf{q_0})\\cdot \\left[\\matrix{k_1 \\cdot \\Delta\\mathbf{r} \\\\ k_2 \\cdot \\mathbf{\\omega}}\\right]\\) , where the inverse can be pseudo-inverse or transposed \\(\\mathbf{q}_{better} = \\mathbf{q}_{0} + \\Delta\\mathbf{q}\\) Exercise 1: Doosan2 install Reset the ~/.bashrc file to ROS2 default. Install the dependencies. sudo apt update sudo apt-get install libpoco-dev sudo apt-get install ros-foxy-control-msgs ros-foxy-realtime-tools ros-foxy-xacro ros-foxy-joint-state-publisher-gui pip3 install kinpy Tip Also download the source of the kinpy package, it may be useful for understanding the API: https://pypi.org/project/kinpy/ Clone and build the repo. mkdir -p ~/doosan2_ws/src cd ~/doosan2_ws/src git clone https://github.com/TamasDNagy/doosan-robot2.git git clone https://github.com/ros-controls/ros2_control.git git clone https://github.com/ros-controls/ros2_controllers.git git clone https://github.com/ros-simulation/gazebo_ros2_control.git cd ros2_control && git reset --hard 3dc62e28e3bc8cf636275825526c11d13b554bb6 && cd .. cd ros2_controllers && git reset --hard 83c494f460f1c8675f4fdd6fb8707b87e81cb197 && cd ... cd cd gazebo_ros2_control && git reset --hard 3dfe04d412d5be4540752e9c1165ccf25d7c51fb && cd .. git clone -b ros2 --single-branch https://github.com/ros-planning/moveit_msgs cd ~/doosan2_ws rosdep update rosdep install --from-paths src --ignore-src --rosdistro foxy -r -y colcon build --cmake-args -DCMAKE_EXPORT_COMPILE_COMMANDS = ON . install/setup.bash rosdep update Warning Already installed on VMs, but update the repo here too: cd ~/doosan2_ws/src/doosan-robot2 git pull cd ~/doosan2_ws colcon build --cmake-args -DCMAKE_EXPORT_COMPILE_COMMANDS = ON Add the following line to the ~/.bashrc file: source ~/doosan2_ws/install/setup.bash Test the simulator in a new window: ros2 launch dsr_launcher2 single_robot_rviz_topic.launch.py model: = a0912 color: = blue 2: Move robot in articulated space Create a new python source file named doosan2_controller.py in ~/ros2_ws/src/ros2_course/ros2_course folder. Specify the new entry point in setup.py in the usual way. Subscribe to the topic publishing the robot's articulation angles (configuration). Create publisher for the topic that can be used to configure the wrist angles. /joint_states /joint_cmd Move the robot to the configuration q = [0.24, -0.3, 1.55, 0.03, 1.8, 0.5] . 3. Kinematics Import the kinpy package and read the urdf file describing the robot: import kinpy as kp self . chain = kp . build_serial_chain_from_urdf ( open ( \"/home/<USERNAME>/doosan2_ws/src/doosan-robot2/dsr_description2/urdf/a0912.blue.urdf\" ) . read (), \"link6\" ) print ( self . chain . get_joint_parameter_names ()) print ( self . chain ) Calculate and print the TCP position in the given configuration using the kinpy package. tg = chain . forward_kinematics ( th1 ) 4: Inverse kinematics with Jacobian inverse method Write a method that implements the inverse kinematics problem on the robot using the Jacobian inverse method presented in the lecture. The orientation is ignored. Move the TCP to the position (0.55, 0.05, 0.45) . Let us diagram the TCP trajectory of TCP using Matplotlib. Write a loop with a stop condition of the appropriate size of delta_r and rclpy.ok() . Calculate the difference between the desired and the current TCP positions ( delta_r ). Scale with the constant k_1 . Set omega to [0.0, 0.0, 0.0] (ignore orientation). Concatenate delta_r and omega . Calculate the Jacobian matrix in the given configuration using the function kp.jacobian.calc_jacobian(...) . Calculate the pseudo-inverse of the Jacobian matrix np.linalg.pinv(...) . Calculate delta_q using the above formula. Increment the joint angles with the obtained values. Bonus: Inverse kinematics with orientation Complete the solution to the previous problem by including orientation in the inverse kinematics calculation. Useful links doosan-robot2 github https://pypi.org/project/kinpy/ https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation https://www.rosroboticslearning.com/jacobian","title":"7. Kinematics, inverse kinematics"},{"location":"07_robotics_principles/#07-kinematics-inverse-kinematics-programming-of-a-simulated-robotic-arm","text":"","title":"07. Kinematics, inverse kinematics, Programming of a simulated robotic arm"},{"location":"07_robotics_principles/#repetition","text":"","title":"Repetition"},{"location":"07_robotics_principles/#3d-transformations","text":"Position: 3 element offset vector Orientation: 3 x 3 rotation matrix additional orientation representations: Euler angles, RPY, angle axis, quaternion Pose (pose): 4 \u00d7 4 transformation matrix Coordinate system (frame): zero point, 3 axis, 3 base vector, right-hand rule Homogeneous transformations: rotation and translation together e.g. \\(\\mathbf{R}\\) for rotation and \\(\\mathbf{v}\\) for translation: \\[ \\mathbf{T} = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right] = \\left[\\matrix{r_{1,1} & r_{1,2} & r_{1,3} & v_x\\\\r_{2,1} & r_{2,2} & r_{2,3} & v_y\\\\r_{3,1} & r_{3,2} & r_{3,3} & v_z\\\\\\ 0 & 0 & 0 & 1 }\\right] \\] Homogeneous coordinates: Vector: add 0, \\(\\mathbf{a_H}=\\left[\\matrix{\\mathbf{a} \\\\ 0}\\right]=\\left[\\matrix{a_x \\\\ a_y \\\\ a_z \\\\ 0}\\right]\\) Point: add 1, \\(\\mathbf{p_H}=\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right]=\\left[\\matrix{p_x \\\\ p_y \\\\ p_z \\\\ 1}\\right]\\) Using transformations is simpler: \\[ \\mathbf{q} = \\mathbf{R}\\mathbf{p} + \\mathbf{v} \\to \\left[\\matrix{\\mathbf{q} \\\\ 1}\\right] = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right]\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right] \\] Degree of freedom (DoF): number of independent quantities.","title":"3D transformations"},{"location":"07_robotics_principles/#robotics-basics","text":"Robot structure: segments (link) and joints Task space (cartesian space): Three-dimensional space where the task, trajectories, obstacles, etc. are defined. TCP (Tool Center Point): coordinate frame fixed to the end effector Base/world frame Joint space : Quantities assigned to the robot's joints, which can be interpreted by the robot's low-level control system. Joint coordinates, velocities, accelerations, torques...","title":"Robotics basics"},{"location":"07_robotics_principles/#lecture","text":"","title":"Lecture"},{"location":"07_robotics_principles/#kinematics-inverse-kinematics","text":"","title":"Kinematics, inverse kinematics"},{"location":"07_robotics_principles/#kinematics","text":"Def. Kinematics Calculating the position of the TCP (or anything else) from the hinge coordinates. Kinematic model Denavit--Hartenberg (DH) convention URDF (Unified Robotics Description Format, XML-based) If the coordinate systems assigned to the segments are \\(base, 1, 2, 3, ..., TCP\\) , the transfomrms between adjacent segments \\(i\\) and \\(i+1\\) are \\(T_{i+1,i}(q_{i+1})\\) (which is a function of the angle of the joint between them), the transfomrms between the base frame and TCP can be written up (for a robot with \\(n\\) joints): \\[ T_{TCP,base}(q_1, \\cdots, q_n) = T_{TCP,n-1}(q_{n}) \\cdot T_{n-1,n-2}(q_{n-1}) \\cdots T_{2,1}(q_2) \\cdot T_{1,base}(q_1) \\cdot base \\]","title":"Kinematics"},{"location":"07_robotics_principles/#inverse-kinematics","text":"Def. Inverse kinematics Compute joint coordinates to achieve (desired) TCP (or any other) pose.","title":"Inverse kinematics"},{"location":"07_robotics_principles/#differential-inverse-kinematics","text":"Def. Differential inverse kinematics Which change in the wrist coordinates achieves the desired small change in the TCP pose (rotation and translation). Jacobi matrix (Jacobian): a matrix of first-order partial derivatives of a vector-valued function. \\[ \\mathbf{J} = \\left[\\matrix{\\frac{\\partial x_1}{\\partial q_1} & \\frac{\\partial x_1}{\\partial q_2} &\\frac{\\partial x_1}{\\partial q_3} & \\dots &\\frac{\\partial x_1}{\\partial q_n} \\\\ \\frac{\\partial x_2}{\\partial q_1} & \\frac{\\partial x_2}{\\partial q_2} &\\frac{\\partial x_2} {\\partial q_3} & \\dots &\\frac{\\partial x_2}{\\partial q_n} \\\\ \\frac{\\partial x_3}{\\partial q_1} & \\frac{\\partial x_3}{\\partial q_2} &\\frac{\\partial x_3}{\\partial q_3} & \\dots &\\frac{\\partial x_3}{\\partial q_n} \\\\ \\vdots &\\vdots &\\vdots &\\ddots &\\vdots \\\\ \\frac{\\partial x_m}{\\partial q_1} & \\frac{\\partial x_m}{\\partial q_2} &\\frac{\\partial x_m}{\\partial q_3} & \\dots &\\frac{\\partial x_m}{\\partial q_n} \\\\}\\right] \\] Jacobi matrix significance in robotics : gives the relationship between joint velocities and TCP velocity. \\[ \\left[\\matrix{\\mathbf{v} \\\\ \\mathbf{\\omega}}\\right] =\\mathbf{J}(\\mathbf{q})\\cdot \\mathbf{\\dot{q}} \\]","title":"Differential inverse kinematics"},{"location":"07_robotics_principles/#inverse-kinematics-using-jacobian-inverse","text":"Calculate the difference between the desired and the current position: \\(\\Delta\\mathbf{r} = \\mathbf{r}_{desired} - \\mathbf{r}_0\\) Calculate the difference in rotations: \\(\\Delta\\mathbf{R} = \\mathbf{R}_{desired}\\mathbf{R}_{0}^{T}\\) , then convert to axis angle representation \\((\\mathbf{t},\\phi)\\) Compute \\(\\Delta\\mathbf{ q}=\\mathbf{J}^{-1}(\\mathbf{q_0})\\cdot \\left[\\matrix{k_1 \\cdot \\Delta\\mathbf{r} \\\\ k_2 \\cdot \\mathbf{\\omega}}\\right]\\) , where the inverse can be pseudo-inverse or transposed \\(\\mathbf{q}_{better} = \\mathbf{q}_{0} + \\Delta\\mathbf{q}\\)","title":"Inverse kinematics using Jacobian inverse"},{"location":"07_robotics_principles/#exercise","text":"","title":"Exercise"},{"location":"07_robotics_principles/#1-doosan2-install","text":"Reset the ~/.bashrc file to ROS2 default. Install the dependencies. sudo apt update sudo apt-get install libpoco-dev sudo apt-get install ros-foxy-control-msgs ros-foxy-realtime-tools ros-foxy-xacro ros-foxy-joint-state-publisher-gui pip3 install kinpy Tip Also download the source of the kinpy package, it may be useful for understanding the API: https://pypi.org/project/kinpy/ Clone and build the repo. mkdir -p ~/doosan2_ws/src cd ~/doosan2_ws/src git clone https://github.com/TamasDNagy/doosan-robot2.git git clone https://github.com/ros-controls/ros2_control.git git clone https://github.com/ros-controls/ros2_controllers.git git clone https://github.com/ros-simulation/gazebo_ros2_control.git cd ros2_control && git reset --hard 3dc62e28e3bc8cf636275825526c11d13b554bb6 && cd .. cd ros2_controllers && git reset --hard 83c494f460f1c8675f4fdd6fb8707b87e81cb197 && cd ... cd cd gazebo_ros2_control && git reset --hard 3dfe04d412d5be4540752e9c1165ccf25d7c51fb && cd .. git clone -b ros2 --single-branch https://github.com/ros-planning/moveit_msgs cd ~/doosan2_ws rosdep update rosdep install --from-paths src --ignore-src --rosdistro foxy -r -y colcon build --cmake-args -DCMAKE_EXPORT_COMPILE_COMMANDS = ON . install/setup.bash rosdep update Warning Already installed on VMs, but update the repo here too: cd ~/doosan2_ws/src/doosan-robot2 git pull cd ~/doosan2_ws colcon build --cmake-args -DCMAKE_EXPORT_COMPILE_COMMANDS = ON Add the following line to the ~/.bashrc file: source ~/doosan2_ws/install/setup.bash Test the simulator in a new window: ros2 launch dsr_launcher2 single_robot_rviz_topic.launch.py model: = a0912 color: = blue","title":"1: Doosan2 install"},{"location":"07_robotics_principles/#2-move-robot-in-articulated-space","text":"Create a new python source file named doosan2_controller.py in ~/ros2_ws/src/ros2_course/ros2_course folder. Specify the new entry point in setup.py in the usual way. Subscribe to the topic publishing the robot's articulation angles (configuration). Create publisher for the topic that can be used to configure the wrist angles. /joint_states /joint_cmd Move the robot to the configuration q = [0.24, -0.3, 1.55, 0.03, 1.8, 0.5] .","title":"2: Move robot in articulated space"},{"location":"07_robotics_principles/#3-kinematics","text":"Import the kinpy package and read the urdf file describing the robot: import kinpy as kp self . chain = kp . build_serial_chain_from_urdf ( open ( \"/home/<USERNAME>/doosan2_ws/src/doosan-robot2/dsr_description2/urdf/a0912.blue.urdf\" ) . read (), \"link6\" ) print ( self . chain . get_joint_parameter_names ()) print ( self . chain ) Calculate and print the TCP position in the given configuration using the kinpy package. tg = chain . forward_kinematics ( th1 )","title":"3. Kinematics"},{"location":"07_robotics_principles/#4-inverse-kinematics-with-jacobian-inverse-method","text":"Write a method that implements the inverse kinematics problem on the robot using the Jacobian inverse method presented in the lecture. The orientation is ignored. Move the TCP to the position (0.55, 0.05, 0.45) . Let us diagram the TCP trajectory of TCP using Matplotlib. Write a loop with a stop condition of the appropriate size of delta_r and rclpy.ok() . Calculate the difference between the desired and the current TCP positions ( delta_r ). Scale with the constant k_1 . Set omega to [0.0, 0.0, 0.0] (ignore orientation). Concatenate delta_r and omega . Calculate the Jacobian matrix in the given configuration using the function kp.jacobian.calc_jacobian(...) . Calculate the pseudo-inverse of the Jacobian matrix np.linalg.pinv(...) . Calculate delta_q using the above formula. Increment the joint angles with the obtained values.","title":"4: Inverse kinematics with Jacobian inverse method"},{"location":"07_robotics_principles/#bonus-inverse-kinematics-with-orientation","text":"Complete the solution to the previous problem by including orientation in the inverse kinematics calculation.","title":"Bonus: Inverse kinematics with orientation"},{"location":"07_robotics_principles/#useful-links","text":"doosan-robot2 github https://pypi.org/project/kinpy/ https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation https://www.rosroboticslearning.com/jacobian","title":"Useful links"},{"location":"arch_da_vinci/","text":"Principles of robotics, programming a da Vinci surgical robot in a simulated environment, ROS1-ROS2 bridge Rigid body motion Def. Rigid body A rigid body is defined as a body on which the distance between two points remains constant in time regardless of the force applied on it. Shape and the volume of the rigid bodies are also constant. The pose of a rigid body can be given by the three coordinates of three of its points that do not lie on the same straight line. The pose of a rigid body can be described in a more expressive way by the three coordinates of one of its points chosen arbitrarily position and the body's orientation . The motion of rigid bodies is composed by two elemental motions: translation and rotation . During translation , all points of the body move along straight, parallel lines. During rotation , the position of the points of the rotational axis are constant, and the other points of the body move along circles in planes perpendicular to the axis of rotation. The free motion of rigid bodies can always be expressed as the superposition of a translational motion and a rotation around a single axis. 3D transformations Position: 3D offset vector Orientation: 3 x 3 rotation matrix further orientation representations: Euler-angles, RPY, angle axis, quaternion Pose : 4 \u00d7 4 (homogenous) transformation matrix Frame : origin, 3 axes, 3 base vectors, right hand rule Homogenous transformation: rotation and translation in one transfromation e.g., for the rotation \\(\\mathbf{R}\\) and translation \\(\\mathbf{v}\\) : \\[ \\mathbf{T} = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right] = \\left[\\matrix{r_{1,1} & r_{1,2} & r_{1,3} & v_x\\\\r_{2,1} & r_{2,2} & r_{2,3} & v_y\\\\r_{3,1} & r_{3,2} & r_{3,3} & v_z\\\\\\ 0 & 0 & 0 & 1 }\\right] \\] Homogenous coordinates: Vector: extended with 0, \\(\\mathbf{a_H}=\\left[\\matrix{\\mathbf{a} \\\\ 0}\\right]=\\left[\\matrix{a_x \\\\ a_y \\\\ a_z \\\\ 0}\\right]\\) Point: extended by 1, \\(\\mathbf{p_H}=\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right]=\\left[\\matrix{p_x \\\\ p_y \\\\ p_z \\\\ 1}\\right]\\) Applying transfomrations is much easier: \\[ \\mathbf{q} = \\mathbf{R}\\mathbf{p} + \\mathbf{v} \\to \\left[\\matrix{\\mathbf{q} \\\\ 1}\\right] = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right]\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right] \\] Degrees of Freedom (DoF): the number of independent parameters. Principles of robotics Robots are built of: segments (or links) \u00e9s joints Task space (or cartesian space): 3D space around us, where the task, endpoint trajectories, obstacles are defined. TCP (Tool Center Point): Frame fixed to the end effector of the robot. Base frame , world frame Joint space : Properties or values regarding the joints. Low-level controller. Joint angles, joint velocities, accelerations, torques.... Python libraries Numpy Python library High dimension arrays and matrices Mathematical functions import numpy as np # Creating ndarrays a = np . zeros ( 3 ) a . shape a . shape = ( 3 , 1 ) a = np . ones ( 5 ) a = np . empty ( 10 ) l = np . linspace ( 5 , 10 , 6 ) r = np . array ([ 1 , 2 ]) # ndarray from python list r = np . array ([[ 1 , 2 ],[ 3 , 4 ]]) type ( r ) # Indexing l [ 0 ] l [ 0 : 2 ] l [ - 1 ] r [:, 0 ] # Operations on ndarrays r_sin = np . sin ( r ) np . max ( r ) np . min ( r ) np . sum ( r ) np . mean ( r ) np . std ( r ) l < 7 l [ l < 7 ] np . where ( l < 7 ) p = np . linspace ( 1 , 5 , 6 ) q = np . linspace ( 10 , 14 , 6 ) s = p + q s = p * q s = p * 10 s = p + 10 s = p @ q # dot product s = r . T If not installed: pip3 install numpy Matplotlib Visualization in python Syntax similar to Matlab import numpy as np from matplotlib import pyplot as plt X = np . linspace ( - np . pi , np . pi , 256 ) C , S = np . cos ( X ), np . sin ( X ) plt . plot ( X , C ) plt . plot ( X , S ) plt . show () If not installed: pip3 install matplotlib Practice 1: ROS1-ROS2 bridge install Open the ~/.bashrc file and comment out the lines responsible for source-coding ROS 1, ROS 2 and additional ROS workspaces. Add the following line to the ~/.bashrc file: export ROS_MASTER_URI = http://localhost:11311 Install the ros-foxy-ros1-bridge package: sudo apt update sudo apt install ros-foxy-ros1-bridge 2: Catkin workspace Install the catkin build tools package: sudo apt update sudo apt-get install python3-catkin-tools python3-osrf-pycommon Create the catkin workspace: mkdir -p ~/catkin_ws/src cd ~/catkin_ws catkin init 3: dVRK install On Ubuntu 20.04 you will need the following packages: sudo apt install libxml2-dev libraw1394-dev libncurses5-dev qtcreator swig sox espeak cmake-curses-gui cmake-qt-gui git subversion gfortran libcppunit-dev libqt5xmlpatterns5-dev python3-wstool python3-catkin-tools python3-osrf-pycommon ros-noetic-rviz Download the script that makes it easy to source ROS versions (already downloaded on VMs). Source ROS 1: cd source ros_setup.sh -v 1 Download and install the dVRK (da Vinci Reserach Kit): cd ~/catkin_ws # go in the workspace wstool init src # we're going to use wstool to pull all the code from github catkin config --cmake-args -DCMAKE_BUILD_TYPE = Release # all code should be compiled in release mode cd src # go in source directory to pull code wstool merge https://raw.githubusercontent.com/jhu-dvrk/dvrk-ros/master/dvrk_ros.rosinstall # or replace master by devel wstool up # now wstool knows which repositories to pull, let's get the code cd ~/catkin_ws catkin build --summary # ... and finally compile everything Danger Never use catkin build and catkin_make in the same workspace! Start the RViz simulation of PSM1 (Patient Side Manipulator). Do not forget to HOME on the dVRK console. Start the ROS1-ROS2 Bridge. Study the simulator operation from ROS 2 using the learned prancs ( ros2 topic list , ros2 topic echo ros2 run rqt_gui rqt_gui , etc.). source ros_setup.sh -v 2 ros2 topic list ros2 topic echo /PSM1/measured_cp ros2 run rqt_gui rqt_gui source ros_setup.sh -v 1 roslaunch dvrk_robot dvrk_arm_rviz.launch arm: = PSM1 config: = /home/ $( whoami ) /catkin_ws/src/cisst-saw/sawIntuitiveResearchKit/share/console/console-PSM1_KIN_SIMULATED.json source ros_setup.sh -v b ros2 run ros1_bridge dynamic_bridge --bridge-all-topics source ros_setup.sh -v 2 ros2 run rqt_gui rqt_gui 4: PSM subscriber Create a new python source file named psm_grasp.py in ~/ros2_ws/src/ros2_course/ros2_course . Specify the new entry point in setup.py in the usual way. --- Subscribe to topics that publish the TCP (Tool Center Point) position of the PSM and the angle of the jaws of the tweezers. /PSM1/measured_cp /PSM1/jaw/measured_js Build and run the node: source ros_setup.sh -v 2 cd ~/ros2_ws colcon build --symlink-install ros2 run ros2_course psm_grasp 5. Moving PSM TCP along a linear trajectory The PSM expects the desired TCP position and the angle closed by the jaws of the clamp in the topics below. Create publishers in psm_grasp.py for these topics. /PSM1/servo_cp /PSM1/jaw/servo_jp Write a function that moves the TCP along a linear trajectory to the desired position. Send the pin to position (0.0, 0.05, -0.12), leave the orientation unchanged. The sampling time should be 0.01s. Using Matplotlib plot the planned trajectory x, y and z components of the projected trajectory as a function of time. def move_tcp_to ( self , target , v , dt ): Write a function to open and close the gripper, also using a linear trajectory. def move_jaw_to ( self , target , omega , dt ): 6. Dummy marker Create a new python source file named dummy_marker.py . Specify the entry point in setup.py in the usual way. Implement a python program that publishes a marker with position (-0.05, 0.08, -0.14) in topic dummy_target_marker . The value of the frame_id add tag should be PSM1_psm_base_link . Copy the following code into the file dummy_marker.py : import rclpy from rclpy.node import Node from visualization_msgs.msg import Marker class DummyMarker ( Node ): def __init__ ( self , position ): super () . __init__ ( 'minimal_publisher' ) self . position = position self . publisher_ = self . create_publisher ( Marker , 'dummy_target_marker' , 10 ) timer_period = 0.1 # seconds self . timer = self . create_timer ( timer_period , self . timer_callback ) self . i = 0 i = 0 def timer_callback ( self ): marker = Marker () marker . header . frame_id = 'PSM1_psm_base_link' marker . header . stamp = self . get_clock () . now () . to_msg () marker . ns = \"dvrk_viz\" marker . id = self . i marker . type = Marker . SPHERE marker . action = Marker . MODIFY marker . pose . position . x = self . position [ 0 ] marker . pose . position . y = self . position [ 1 ] marker . pose . position . z = self . position [ 2 ] marker . pose . orientation . x = 0.0 marker . pose . orientation . y = 0.0 marker . pose . orientation . z = 0.0 marker . pose . orientation . w = 1.0 marker . scale . x = 0.008 marker . scale . y = 0.008 marker . scale . z = 0.008 marker . color . a = 1.0 # Don't forget to set the alpha! marker . color . r = 0.0 marker . color . g = 1.0 marker . color . b = 0.0 ; self . publisher_ . publish ( marker ) self . i += 1 def main ( args = None ): rclpy . init ( args = args ) marker_publisher = DummyMarker ([ - 0.05 , 0.08 , - 0.12 ]) rclpy . spin ( marker_publisher ) # Destroy the node explicitly # (optional - otherwise it will be done automatically # when the garbage collector destroys the node object) marker_publisher . destroy_node () rclpy . shutdown () if __name__ == '__main__' : main () Run the node and display the marker in RViz. 7. Grasping the marker Subscribe to the topic sending the marker position in psm_grasp.py . Modify psm_grasp.py to use the tweezers to grasp the generated marker. !!! note The simulator used has a tendency for certain values to get \"stuck\", so it is a good idea to reset the lever at the beginning of the program using the following lines: #Reset the arm psm . move_tcp_to ([ 0.0 , 0.0 , - 0.12 ], 0.01 , 0.01 ) psm . move_jaw_to ( 0.0 , 0.1 , 0.01 ) USeful links Download and compile dVRK Marker examples Numpy vector magnitude Numpy linspace","title":"Principles of robotics, da Vinci (ROS1-ROS2 bridge)"},{"location":"arch_da_vinci/#principles-of-robotics-programming-a-da-vinci-surgical-robot-in-a-simulated-environment-ros1-ros2-bridge","text":"","title":"Principles of robotics, programming a da Vinci surgical robot in a simulated environment, ROS1-ROS2 bridge"},{"location":"arch_da_vinci/#rigid-body-motion","text":"Def. Rigid body A rigid body is defined as a body on which the distance between two points remains constant in time regardless of the force applied on it. Shape and the volume of the rigid bodies are also constant. The pose of a rigid body can be given by the three coordinates of three of its points that do not lie on the same straight line. The pose of a rigid body can be described in a more expressive way by the three coordinates of one of its points chosen arbitrarily position and the body's orientation . The motion of rigid bodies is composed by two elemental motions: translation and rotation . During translation , all points of the body move along straight, parallel lines. During rotation , the position of the points of the rotational axis are constant, and the other points of the body move along circles in planes perpendicular to the axis of rotation. The free motion of rigid bodies can always be expressed as the superposition of a translational motion and a rotation around a single axis.","title":"Rigid body motion"},{"location":"arch_da_vinci/#3d-transformations","text":"Position: 3D offset vector Orientation: 3 x 3 rotation matrix further orientation representations: Euler-angles, RPY, angle axis, quaternion Pose : 4 \u00d7 4 (homogenous) transformation matrix Frame : origin, 3 axes, 3 base vectors, right hand rule Homogenous transformation: rotation and translation in one transfromation e.g., for the rotation \\(\\mathbf{R}\\) and translation \\(\\mathbf{v}\\) : \\[ \\mathbf{T} = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right] = \\left[\\matrix{r_{1,1} & r_{1,2} & r_{1,3} & v_x\\\\r_{2,1} & r_{2,2} & r_{2,3} & v_y\\\\r_{3,1} & r_{3,2} & r_{3,3} & v_z\\\\\\ 0 & 0 & 0 & 1 }\\right] \\] Homogenous coordinates: Vector: extended with 0, \\(\\mathbf{a_H}=\\left[\\matrix{\\mathbf{a} \\\\ 0}\\right]=\\left[\\matrix{a_x \\\\ a_y \\\\ a_z \\\\ 0}\\right]\\) Point: extended by 1, \\(\\mathbf{p_H}=\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right]=\\left[\\matrix{p_x \\\\ p_y \\\\ p_z \\\\ 1}\\right]\\) Applying transfomrations is much easier: \\[ \\mathbf{q} = \\mathbf{R}\\mathbf{p} + \\mathbf{v} \\to \\left[\\matrix{\\mathbf{q} \\\\ 1}\\right] = \\left[\\matrix{\\mathbf{R} & \\mathbf{v}\\\\\\mathbf{0} & 1 }\\right]\\left[\\matrix{\\mathbf{p} \\\\ 1}\\right] \\] Degrees of Freedom (DoF): the number of independent parameters.","title":"3D transformations"},{"location":"arch_da_vinci/#principles-of-robotics","text":"Robots are built of: segments (or links) \u00e9s joints Task space (or cartesian space): 3D space around us, where the task, endpoint trajectories, obstacles are defined. TCP (Tool Center Point): Frame fixed to the end effector of the robot. Base frame , world frame Joint space : Properties or values regarding the joints. Low-level controller. Joint angles, joint velocities, accelerations, torques....","title":"Principles of robotics"},{"location":"arch_da_vinci/#python-libraries","text":"","title":"Python libraries"},{"location":"arch_da_vinci/#numpy","text":"Python library High dimension arrays and matrices Mathematical functions import numpy as np # Creating ndarrays a = np . zeros ( 3 ) a . shape a . shape = ( 3 , 1 ) a = np . ones ( 5 ) a = np . empty ( 10 ) l = np . linspace ( 5 , 10 , 6 ) r = np . array ([ 1 , 2 ]) # ndarray from python list r = np . array ([[ 1 , 2 ],[ 3 , 4 ]]) type ( r ) # Indexing l [ 0 ] l [ 0 : 2 ] l [ - 1 ] r [:, 0 ] # Operations on ndarrays r_sin = np . sin ( r ) np . max ( r ) np . min ( r ) np . sum ( r ) np . mean ( r ) np . std ( r ) l < 7 l [ l < 7 ] np . where ( l < 7 ) p = np . linspace ( 1 , 5 , 6 ) q = np . linspace ( 10 , 14 , 6 ) s = p + q s = p * q s = p * 10 s = p + 10 s = p @ q # dot product s = r . T If not installed: pip3 install numpy","title":"Numpy"},{"location":"arch_da_vinci/#matplotlib","text":"Visualization in python Syntax similar to Matlab import numpy as np from matplotlib import pyplot as plt X = np . linspace ( - np . pi , np . pi , 256 ) C , S = np . cos ( X ), np . sin ( X ) plt . plot ( X , C ) plt . plot ( X , S ) plt . show () If not installed: pip3 install matplotlib","title":"Matplotlib"},{"location":"arch_da_vinci/#practice","text":"","title":"Practice"},{"location":"arch_da_vinci/#1-ros1-ros2-bridge-install","text":"Open the ~/.bashrc file and comment out the lines responsible for source-coding ROS 1, ROS 2 and additional ROS workspaces. Add the following line to the ~/.bashrc file: export ROS_MASTER_URI = http://localhost:11311 Install the ros-foxy-ros1-bridge package: sudo apt update sudo apt install ros-foxy-ros1-bridge","title":"1: ROS1-ROS2 bridge install"},{"location":"arch_da_vinci/#2-catkin-workspace","text":"Install the catkin build tools package: sudo apt update sudo apt-get install python3-catkin-tools python3-osrf-pycommon Create the catkin workspace: mkdir -p ~/catkin_ws/src cd ~/catkin_ws catkin init","title":"2: Catkin workspace"},{"location":"arch_da_vinci/#3-dvrk-install","text":"On Ubuntu 20.04 you will need the following packages: sudo apt install libxml2-dev libraw1394-dev libncurses5-dev qtcreator swig sox espeak cmake-curses-gui cmake-qt-gui git subversion gfortran libcppunit-dev libqt5xmlpatterns5-dev python3-wstool python3-catkin-tools python3-osrf-pycommon ros-noetic-rviz Download the script that makes it easy to source ROS versions (already downloaded on VMs). Source ROS 1: cd source ros_setup.sh -v 1 Download and install the dVRK (da Vinci Reserach Kit): cd ~/catkin_ws # go in the workspace wstool init src # we're going to use wstool to pull all the code from github catkin config --cmake-args -DCMAKE_BUILD_TYPE = Release # all code should be compiled in release mode cd src # go in source directory to pull code wstool merge https://raw.githubusercontent.com/jhu-dvrk/dvrk-ros/master/dvrk_ros.rosinstall # or replace master by devel wstool up # now wstool knows which repositories to pull, let's get the code cd ~/catkin_ws catkin build --summary # ... and finally compile everything Danger Never use catkin build and catkin_make in the same workspace! Start the RViz simulation of PSM1 (Patient Side Manipulator). Do not forget to HOME on the dVRK console. Start the ROS1-ROS2 Bridge. Study the simulator operation from ROS 2 using the learned prancs ( ros2 topic list , ros2 topic echo ros2 run rqt_gui rqt_gui , etc.). source ros_setup.sh -v 2 ros2 topic list ros2 topic echo /PSM1/measured_cp ros2 run rqt_gui rqt_gui source ros_setup.sh -v 1 roslaunch dvrk_robot dvrk_arm_rviz.launch arm: = PSM1 config: = /home/ $( whoami ) /catkin_ws/src/cisst-saw/sawIntuitiveResearchKit/share/console/console-PSM1_KIN_SIMULATED.json source ros_setup.sh -v b ros2 run ros1_bridge dynamic_bridge --bridge-all-topics source ros_setup.sh -v 2 ros2 run rqt_gui rqt_gui","title":"3: dVRK install"},{"location":"arch_da_vinci/#4-psm-subscriber","text":"Create a new python source file named psm_grasp.py in ~/ros2_ws/src/ros2_course/ros2_course . Specify the new entry point in setup.py in the usual way. --- Subscribe to topics that publish the TCP (Tool Center Point) position of the PSM and the angle of the jaws of the tweezers. /PSM1/measured_cp /PSM1/jaw/measured_js Build and run the node: source ros_setup.sh -v 2 cd ~/ros2_ws colcon build --symlink-install ros2 run ros2_course psm_grasp","title":"4: PSM subscriber"},{"location":"arch_da_vinci/#5-moving-psm-tcp-along-a-linear-trajectory","text":"The PSM expects the desired TCP position and the angle closed by the jaws of the clamp in the topics below. Create publishers in psm_grasp.py for these topics. /PSM1/servo_cp /PSM1/jaw/servo_jp Write a function that moves the TCP along a linear trajectory to the desired position. Send the pin to position (0.0, 0.05, -0.12), leave the orientation unchanged. The sampling time should be 0.01s. Using Matplotlib plot the planned trajectory x, y and z components of the projected trajectory as a function of time. def move_tcp_to ( self , target , v , dt ): Write a function to open and close the gripper, also using a linear trajectory. def move_jaw_to ( self , target , omega , dt ):","title":"5. Moving PSM TCP along a linear trajectory"},{"location":"arch_da_vinci/#6-dummy-marker","text":"Create a new python source file named dummy_marker.py . Specify the entry point in setup.py in the usual way. Implement a python program that publishes a marker with position (-0.05, 0.08, -0.14) in topic dummy_target_marker . The value of the frame_id add tag should be PSM1_psm_base_link . Copy the following code into the file dummy_marker.py : import rclpy from rclpy.node import Node from visualization_msgs.msg import Marker class DummyMarker ( Node ): def __init__ ( self , position ): super () . __init__ ( 'minimal_publisher' ) self . position = position self . publisher_ = self . create_publisher ( Marker , 'dummy_target_marker' , 10 ) timer_period = 0.1 # seconds self . timer = self . create_timer ( timer_period , self . timer_callback ) self . i = 0 i = 0 def timer_callback ( self ): marker = Marker () marker . header . frame_id = 'PSM1_psm_base_link' marker . header . stamp = self . get_clock () . now () . to_msg () marker . ns = \"dvrk_viz\" marker . id = self . i marker . type = Marker . SPHERE marker . action = Marker . MODIFY marker . pose . position . x = self . position [ 0 ] marker . pose . position . y = self . position [ 1 ] marker . pose . position . z = self . position [ 2 ] marker . pose . orientation . x = 0.0 marker . pose . orientation . y = 0.0 marker . pose . orientation . z = 0.0 marker . pose . orientation . w = 1.0 marker . scale . x = 0.008 marker . scale . y = 0.008 marker . scale . z = 0.008 marker . color . a = 1.0 # Don't forget to set the alpha! marker . color . r = 0.0 marker . color . g = 1.0 marker . color . b = 0.0 ; self . publisher_ . publish ( marker ) self . i += 1 def main ( args = None ): rclpy . init ( args = args ) marker_publisher = DummyMarker ([ - 0.05 , 0.08 , - 0.12 ]) rclpy . spin ( marker_publisher ) # Destroy the node explicitly # (optional - otherwise it will be done automatically # when the garbage collector destroys the node object) marker_publisher . destroy_node () rclpy . shutdown () if __name__ == '__main__' : main () Run the node and display the marker in RViz.","title":"6. Dummy marker"},{"location":"arch_da_vinci/#7-grasping-the-marker","text":"Subscribe to the topic sending the marker position in psm_grasp.py . Modify psm_grasp.py to use the tweezers to grasp the generated marker. !!! note The simulator used has a tendency for certain values to get \"stuck\", so it is a good idea to reset the lever at the beginning of the program using the following lines: #Reset the arm psm . move_tcp_to ([ 0.0 , 0.0 , - 0.12 ], 0.01 , 0.01 ) psm . move_jaw_to ( 0.0 , 0.1 , 0.01 )","title":"7. Grasping the marker"},{"location":"arch_da_vinci/#useful-links","text":"Download and compile dVRK Marker examples Numpy vector magnitude Numpy linspace","title":"USeful links"},{"location":"arch_sensory_data/","text":"Gathering and processing sensory data Practice 1: Leo Rover Install the Leo rover ROS packages: sudo apt update sudo apt install ros-noetic-leo* Start the Gazebo simulator with the Mars landscape using the instructions from http://wiki.ros.org/leo_gazebo. Start the teleop node and move the robot. 2: Coffee on Mars - Capturing Images Warning The Mars rover sent an image of an unusual object that looks like a coffee mug! The task is to turn the rover towards the mug and approach it for detailed examination. Start Gazebo: gazebo In the insert panel, search for the googleresearch/models/cole_hardware_mug_classic_blue model and place it in the simulation. This is necessary to have the mug model in our file system later. Close Gazebo. Download the leo_masryard_coffee.launch and marsyard_coffe.world files, then copy them to the catkin_ws/src/ros_course/launch and catkin_ws/src/ros_course/worlds directories respectively. Modify the file paths /home/tamas/.ignition/fuel/fuel... in the .world files to match your own. Launch the simulator: roslaunch ros_course leo_marsyard_coffee.launch Start the teleop and rqt_image_view : rosrun leo_teleop key_teleop rosrun rqt_image_view rqt_image_view Capture images showing the coffee mug being visible and not visible. 3: Coffee on Mars - Offline Image Processing Write a Python script to read and display the captured images. Perform color-based segmentation (or any other method) to segment the coffee mug. Determine the center of the mug in image coordinates. Filter out the noise caused by segmentation. 4: Coffee on Mars - Online Perception Node Subscribe to the /camera/image_raw topic and display the received images using the cv.imshow() function. Integrate our working computer vision algorithm into a ROS node. Publish the detected mug's center coordinates in a new topic. You can use types like Int32MultiArray , Point2D , or define your own (the mug size will be needed later). Bonus: Publish the mask and masked image in separate Image topics. 5: Coffee on Mars - Operation Logic Node Write a new ROS node that receives messages from the perception node and is capable of controlling the rover's movement. Rotate the rover in place until the mug is in the center of the image. Approach the mug until its apparent size does not exceed 50% of the image size. Capture an image of the suspicious object. 5+1: Bonus Explore the insertable models in Gazebo's insert panel and choose one that can be detected on the camera image using a different method (e.g., template matching). Modify the nodes to approach this object with the rover. Useful links http://wiki.ros.org/leo_gazebo http://wiki.ros.org/cv_bridge/Tutorials/ConvertingBetweenROSImagesAndOpenCVImagesPython https://realpython.com/python-opencv-color-spaces/ https://stackoverflow.com/questions/59164192/how-to-find-the-contour-of-a-blob-using-opencv-python Turtlebot","title":"Gathering and processign sensory data (ROS1)"},{"location":"arch_sensory_data/#gathering-and-processing-sensory-data","text":"","title":"Gathering and processing sensory data"},{"location":"arch_sensory_data/#practice","text":"","title":"Practice"},{"location":"arch_sensory_data/#1-leo-rover","text":"Install the Leo rover ROS packages: sudo apt update sudo apt install ros-noetic-leo* Start the Gazebo simulator with the Mars landscape using the instructions from http://wiki.ros.org/leo_gazebo. Start the teleop node and move the robot.","title":"1: Leo Rover"},{"location":"arch_sensory_data/#2-coffee-on-mars-capturing-images","text":"Warning The Mars rover sent an image of an unusual object that looks like a coffee mug! The task is to turn the rover towards the mug and approach it for detailed examination. Start Gazebo: gazebo In the insert panel, search for the googleresearch/models/cole_hardware_mug_classic_blue model and place it in the simulation. This is necessary to have the mug model in our file system later. Close Gazebo. Download the leo_masryard_coffee.launch and marsyard_coffe.world files, then copy them to the catkin_ws/src/ros_course/launch and catkin_ws/src/ros_course/worlds directories respectively. Modify the file paths /home/tamas/.ignition/fuel/fuel... in the .world files to match your own. Launch the simulator: roslaunch ros_course leo_marsyard_coffee.launch Start the teleop and rqt_image_view : rosrun leo_teleop key_teleop rosrun rqt_image_view rqt_image_view Capture images showing the coffee mug being visible and not visible.","title":"2: Coffee on Mars - Capturing Images"},{"location":"arch_sensory_data/#3-coffee-on-mars-offline-image-processing","text":"Write a Python script to read and display the captured images. Perform color-based segmentation (or any other method) to segment the coffee mug. Determine the center of the mug in image coordinates. Filter out the noise caused by segmentation.","title":"3: Coffee on Mars - Offline Image Processing"},{"location":"arch_sensory_data/#4-coffee-on-mars-online-perception-node","text":"Subscribe to the /camera/image_raw topic and display the received images using the cv.imshow() function. Integrate our working computer vision algorithm into a ROS node. Publish the detected mug's center coordinates in a new topic. You can use types like Int32MultiArray , Point2D , or define your own (the mug size will be needed later). Bonus: Publish the mask and masked image in separate Image topics.","title":"4: Coffee on Mars - Online Perception Node"},{"location":"arch_sensory_data/#5-coffee-on-mars-operation-logic-node","text":"Write a new ROS node that receives messages from the perception node and is capable of controlling the rover's movement. Rotate the rover in place until the mug is in the center of the image. Approach the mug until its apparent size does not exceed 50% of the image size. Capture an image of the suspicious object.","title":"5: Coffee on Mars - Operation Logic Node"},{"location":"arch_sensory_data/#51-bonus","text":"Explore the insertable models in Gazebo's insert panel and choose one that can be detected on the camera image using a different method (e.g., template matching). Modify the nodes to approach this object with the rover.","title":"5+1: Bonus"},{"location":"arch_sensory_data/#useful-links","text":"http://wiki.ros.org/leo_gazebo http://wiki.ros.org/cv_bridge/Tutorials/ConvertingBetweenROSImagesAndOpenCVImagesPython https://realpython.com/python-opencv-color-spaces/ https://stackoverflow.com/questions/59164192/how-to-find-the-contour-of-a-blob-using-opencv-python Turtlebot","title":"Useful links"},{"location":"projects/","text":"Projects Challenge levels and grades Projects can be completed at three Challenge levels . The Challenge level determines the best grade that can be received to the project! Challenge level Best grade Basic 3 Advanced 4 Epic 5 Tip The projects are defined in a way that it is recommended to tart with the Basic level, and then gradually work towards Epic . The projects are graded based on the follwoing aspects: Proved to be the student's own work Running results valid output Usage of versioning, usage of GitHub/GitLab/other repository Launch files Completeness of the solution Proper ROS communication Proper structure of the program Quality of implementation Documentation quality Schedule Week Date Event 8. April 18 Project lab I. 13. May 23 Project lab II. 14. May 30 Project presentations. Grading To pass the course, Tests and the Project must be passed (grade 2). One of the Test can be taken again. Grade \\(Grade = (Test1 + Test2 + 2 \\times Project) / 4\\) --- Project topics 1. TurtleBot3 TurtleBot3 ROS tutorial 1.1. TurtleBot obstacle avoidance Basic: Simulator animation, SLAM testing. Implement ROS node/nodes to read sensor data and move the robot. Advanced: Implement ROS system to detect obstacle and plan and implement obstacle avoidance trajectory in simulated environment using any sensor. Epic: Impress me! 1.2. TurtleBot path following Basic: Simulator animation, SLAM testing. Implement ROS node/nodes to read sensor data and move the robot. Advanced: Implement ROS system for tracking in a simulated environment using any sensor (e.g. passing a wall at a given distance using LIDAR). Epic: Impress me! Image source: https://robots.ros.org/turtlebot3/ 1.3. TurtleBot object tracking/visual servoing Basic: Simulator animation, SLAM testing. Implement ROS node/nodes to read sensor data and move the robot. Advanced: Implement ROS system to find/recognize object and track/move it in simulated environment using any sensor (e.g. visual servoing). Epic: Impress me! 1.4. TurtleBot action library Basic: Simulator animation, SLAM testing. Implement ROS node/nodes to read sensor data and move the robot. Advanced: Implement a ROS action-based library of simple operations and a system to execute them (e.g. push object, move to object, turn around). Epic: Impress me! 2. YouBot YouBot controller GitHub 2.1. YouBot ROS integration Basic: YouBot repo build, getting to know it Advanced: Moving a simulated robot in an articulated ROS environment Epic: Testing on real robot and/or impress me! 3. AMBF AMBF GitHub Building AMBF Fork AMBF, then clone our fork: cd ~/ros2_ws/src git clone <MY_AMBF_FORK.git> Don't use make as suggested in the AMBF documentation, use colcon: cd ~/ros2_ws colcon build --symlink-install Launch the simulator: cd ~/ros2_ws/src/ambf/bin/lin-x86_64 ./ambf_simulator -l 4 3.1. AMBF da Vinci ROS integration Basic: Simulator animation, robot control in joint space and task space (IK already implemented in AMBF) from ROS via CRTK topics Advanced: Object detection in *Peg transfer puzzle Epic: Autonomous manipulation in Peg transfer and/or impress me! 3.2. AMBF KUKA arm ROS integration Basic: Simulator animation, robot control in joint space from ROS Advanced: Generate trajectories in joint space Epic: Implement inverse kinematics and/or impress me! 3.3. AMBF PR2 humanoid ROS integration Basic: Simulator animation, robot control in joint space from ROS Advanced: Robot control in task space, IK? Epic: Trajectory planning/Navigation/Manipulation and/or impress me! X. Own topic By discussion. Useful links TurtleBot3 Simulation TurtleBot3 Tutorial AMBF My fork of AMBF CRTK topics Navigation stack Paper on LiDAR SLAM Paper on vSLAM Paper on Visual Servoing Mobile Robot","title":"Projects"},{"location":"projects/#projects","text":"","title":"Projects"},{"location":"projects/#challenge-levels-and-grades","text":"Projects can be completed at three Challenge levels . The Challenge level determines the best grade that can be received to the project! Challenge level Best grade Basic 3 Advanced 4 Epic 5 Tip The projects are defined in a way that it is recommended to tart with the Basic level, and then gradually work towards Epic . The projects are graded based on the follwoing aspects: Proved to be the student's own work Running results valid output Usage of versioning, usage of GitHub/GitLab/other repository Launch files Completeness of the solution Proper ROS communication Proper structure of the program Quality of implementation Documentation quality","title":"Challenge levels and grades"},{"location":"projects/#schedule","text":"Week Date Event 8. April 18 Project lab I. 13. May 23 Project lab II. 14. May 30 Project presentations.","title":"Schedule"},{"location":"projects/#grading","text":"To pass the course, Tests and the Project must be passed (grade 2). One of the Test can be taken again. Grade \\(Grade = (Test1 + Test2 + 2 \\times Project) / 4\\)","title":"Grading"},{"location":"projects/#-","text":"","title":"---"},{"location":"projects/#project-topics","text":"","title":"Project topics"},{"location":"projects/#1-turtlebot3","text":"TurtleBot3 ROS tutorial","title":"1. TurtleBot3"},{"location":"projects/#11-turtlebot-obstacle-avoidance","text":"Basic: Simulator animation, SLAM testing. Implement ROS node/nodes to read sensor data and move the robot. Advanced: Implement ROS system to detect obstacle and plan and implement obstacle avoidance trajectory in simulated environment using any sensor. Epic: Impress me!","title":"1.1. TurtleBot obstacle avoidance"},{"location":"projects/#12-turtlebot-path-following","text":"Basic: Simulator animation, SLAM testing. Implement ROS node/nodes to read sensor data and move the robot. Advanced: Implement ROS system for tracking in a simulated environment using any sensor (e.g. passing a wall at a given distance using LIDAR). Epic: Impress me! Image source: https://robots.ros.org/turtlebot3/","title":"1.2. TurtleBot path following"},{"location":"projects/#13-turtlebot-object-trackingvisual-servoing","text":"Basic: Simulator animation, SLAM testing. Implement ROS node/nodes to read sensor data and move the robot. Advanced: Implement ROS system to find/recognize object and track/move it in simulated environment using any sensor (e.g. visual servoing). Epic: Impress me!","title":"1.3. TurtleBot object tracking/visual servoing"},{"location":"projects/#14-turtlebot-action-library","text":"Basic: Simulator animation, SLAM testing. Implement ROS node/nodes to read sensor data and move the robot. Advanced: Implement a ROS action-based library of simple operations and a system to execute them (e.g. push object, move to object, turn around). Epic: Impress me!","title":"1.4. TurtleBot action library"},{"location":"projects/#2-youbot","text":"YouBot controller GitHub","title":"2. YouBot"},{"location":"projects/#21-youbot-ros-integration","text":"Basic: YouBot repo build, getting to know it Advanced: Moving a simulated robot in an articulated ROS environment Epic: Testing on real robot and/or impress me!","title":"2.1. YouBot ROS integration"},{"location":"projects/#3-ambf","text":"AMBF GitHub Building AMBF Fork AMBF, then clone our fork: cd ~/ros2_ws/src git clone <MY_AMBF_FORK.git> Don't use make as suggested in the AMBF documentation, use colcon: cd ~/ros2_ws colcon build --symlink-install Launch the simulator: cd ~/ros2_ws/src/ambf/bin/lin-x86_64 ./ambf_simulator -l 4","title":"3. AMBF"},{"location":"projects/#31-ambf-da-vinci-ros-integration","text":"Basic: Simulator animation, robot control in joint space and task space (IK already implemented in AMBF) from ROS via CRTK topics Advanced: Object detection in *Peg transfer puzzle Epic: Autonomous manipulation in Peg transfer and/or impress me!","title":"3.1. AMBF da Vinci ROS integration"},{"location":"projects/#32-ambf-kuka-arm-ros-integration","text":"Basic: Simulator animation, robot control in joint space from ROS Advanced: Generate trajectories in joint space Epic: Implement inverse kinematics and/or impress me!","title":"3.2. AMBF KUKA arm ROS integration"},{"location":"projects/#33-ambf-pr2-humanoid-ros-integration","text":"Basic: Simulator animation, robot control in joint space from ROS Advanced: Robot control in task space, IK? Epic: Trajectory planning/Navigation/Manipulation and/or impress me!","title":"3.3. AMBF PR2 humanoid ROS integration"},{"location":"projects/#x-own-topic","text":"By discussion.","title":"X. Own topic"},{"location":"projects/#useful-links","text":"TurtleBot3 Simulation TurtleBot3 Tutorial AMBF My fork of AMBF CRTK topics Navigation stack Paper on LiDAR SLAM Paper on vSLAM Paper on Visual Servoing Mobile Robot","title":"Useful links"}]}